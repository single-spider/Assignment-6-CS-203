{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "XDgv_aoNtS3n"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "!pip install autogluon -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HeQpUiZpUJji"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK044mQenYdl",
        "outputId": "dd81e2df-3552-4f31-cfb3-3b49b333b6fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "# You will have to provide an API key for the graphs to be shown in wandb, for that you have to create an account on https://www.wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HBrWmPB_rdPG",
        "outputId": "8cad6f98-273a-4ee4-f8e0-41f420c23d13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250226_174811-qcy1ey3y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris/runs/qcy1ey3y' target=\"_blank\">mlp-experiment</a></strong> to <a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris' target=\"_blank\">https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris/runs/qcy1ey3y' target=\"_blank\">https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris/runs/qcy1ey3y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.2279 - loss: 1.0950 - val_accuracy: 0.3333 - val_loss: 1.0873\n",
            "Epoch 2/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3493 - loss: 1.0814 - val_accuracy: 0.3333 - val_loss: 1.0757\n",
            "Epoch 3/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3562 - loss: 1.0727 - val_accuracy: 0.4000 - val_loss: 1.0640\n",
            "Epoch 4/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3774 - loss: 1.0609 - val_accuracy: 0.4000 - val_loss: 1.0527\n",
            "Epoch 5/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.3191 - loss: 1.0556 - val_accuracy: 0.4000 - val_loss: 1.0416\n",
            "Epoch 6/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3635 - loss: 1.0389 - val_accuracy: 0.4000 - val_loss: 1.0294\n",
            "Epoch 7/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.3448 - loss: 1.0330 - val_accuracy: 0.5333 - val_loss: 1.0175\n",
            "Epoch 8/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.4613 - loss: 1.0249 - val_accuracy: 0.7333 - val_loss: 1.0057\n",
            "Epoch 9/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5504 - loss: 1.0158 - val_accuracy: 0.8000 - val_loss: 0.9945\n",
            "Epoch 10/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5459 - loss: 1.0049 - val_accuracy: 0.8667 - val_loss: 0.9827\n",
            "Epoch 11/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6469 - loss: 0.9947 - val_accuracy: 0.8667 - val_loss: 0.9707\n",
            "Epoch 12/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6309 - loss: 0.9862 - val_accuracy: 0.8667 - val_loss: 0.9595\n",
            "Epoch 13/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6445 - loss: 0.9729 - val_accuracy: 0.8667 - val_loss: 0.9476\n",
            "Epoch 14/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6663 - loss: 0.9658 - val_accuracy: 0.8667 - val_loss: 0.9360\n",
            "Epoch 15/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6340 - loss: 0.9587 - val_accuracy: 0.8667 - val_loss: 0.9248\n",
            "Epoch 16/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6570 - loss: 0.9445 - val_accuracy: 0.8667 - val_loss: 0.9130\n",
            "Epoch 17/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6143 - loss: 0.9385 - val_accuracy: 0.8667 - val_loss: 0.9020\n",
            "Epoch 18/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6351 - loss: 0.9323 - val_accuracy: 0.8667 - val_loss: 0.8916\n",
            "Epoch 19/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6559 - loss: 0.9166 - val_accuracy: 0.8667 - val_loss: 0.8814\n",
            "Epoch 20/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6653 - loss: 0.9080 - val_accuracy: 0.8667 - val_loss: 0.8714\n",
            "Epoch 21/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6736 - loss: 0.8978 - val_accuracy: 0.8667 - val_loss: 0.8618\n",
            "Epoch 22/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6372 - loss: 0.8967 - val_accuracy: 0.8667 - val_loss: 0.8527\n",
            "Epoch 23/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6518 - loss: 0.8822 - val_accuracy: 0.8667 - val_loss: 0.8439\n",
            "Epoch 24/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6601 - loss: 0.8745 - val_accuracy: 0.8667 - val_loss: 0.8353\n",
            "Epoch 25/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6153 - loss: 0.8776 - val_accuracy: 0.8667 - val_loss: 0.8264\n",
            "Epoch 26/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6705 - loss: 0.8592 - val_accuracy: 0.8667 - val_loss: 0.8168\n",
            "Epoch 27/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6715 - loss: 0.8510 - val_accuracy: 0.8667 - val_loss: 0.8067\n",
            "Epoch 28/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6476 - loss: 0.8506 - val_accuracy: 0.8667 - val_loss: 0.7973\n",
            "Epoch 29/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7163 - loss: 0.8269 - val_accuracy: 0.8667 - val_loss: 0.7873\n",
            "Epoch 30/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6455 - loss: 0.8365 - val_accuracy: 0.8667 - val_loss: 0.7789\n",
            "Epoch 31/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6674 - loss: 0.8246 - val_accuracy: 0.8667 - val_loss: 0.7699\n",
            "Epoch 32/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6715 - loss: 0.8118 - val_accuracy: 0.8667 - val_loss: 0.7612\n",
            "Epoch 33/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6413 - loss: 0.8176 - val_accuracy: 0.8667 - val_loss: 0.7525\n",
            "Epoch 34/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6705 - loss: 0.7962 - val_accuracy: 0.8667 - val_loss: 0.7430\n",
            "Epoch 35/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6736 - loss: 0.7937 - val_accuracy: 0.8667 - val_loss: 0.7332\n",
            "Epoch 36/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6413 - loss: 0.7914 - val_accuracy: 0.8667 - val_loss: 0.7243\n",
            "Epoch 37/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6288 - loss: 0.7942 - val_accuracy: 0.8667 - val_loss: 0.7150\n",
            "Epoch 38/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6590 - loss: 0.7759 - val_accuracy: 0.8667 - val_loss: 0.7045\n",
            "Epoch 39/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6455 - loss: 0.7671 - val_accuracy: 0.8667 - val_loss: 0.6946\n",
            "Epoch 40/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6288 - loss: 0.7654 - val_accuracy: 0.8667 - val_loss: 0.6848\n",
            "Epoch 41/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6038 - loss: 0.7712 - val_accuracy: 0.8667 - val_loss: 0.6758\n",
            "Epoch 42/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6549 - loss: 0.7481 - val_accuracy: 0.8667 - val_loss: 0.6663\n",
            "Epoch 43/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6445 - loss: 0.7432 - val_accuracy: 0.8667 - val_loss: 0.6568\n",
            "Epoch 44/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6403 - loss: 0.7397 - val_accuracy: 0.8667 - val_loss: 0.6476\n",
            "Epoch 45/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6528 - loss: 0.7275 - val_accuracy: 0.8667 - val_loss: 0.6388\n",
            "Epoch 46/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6424 - loss: 0.7291 - val_accuracy: 0.8667 - val_loss: 0.6299\n",
            "Epoch 47/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6570 - loss: 0.7161 - val_accuracy: 0.8667 - val_loss: 0.6219\n",
            "Epoch 48/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6611 - loss: 0.7081 - val_accuracy: 0.8667 - val_loss: 0.6141\n",
            "Epoch 49/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6483 - loss: 0.7083 - val_accuracy: 0.8667 - val_loss: 0.6061\n",
            "Epoch 50/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6549 - loss: 0.6971 - val_accuracy: 0.8667 - val_loss: 0.5983\n",
            "Epoch 51/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6410 - loss: 0.7025 - val_accuracy: 0.8667 - val_loss: 0.5915\n",
            "Epoch 52/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6868 - loss: 0.6843 - val_accuracy: 0.8667 - val_loss: 0.5843\n",
            "Epoch 53/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6743 - loss: 0.6757 - val_accuracy: 0.8667 - val_loss: 0.5773\n",
            "Epoch 54/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6566 - loss: 0.6754 - val_accuracy: 0.8667 - val_loss: 0.5697\n",
            "Epoch 55/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6764 - loss: 0.6603 - val_accuracy: 0.8667 - val_loss: 0.5623\n",
            "Epoch 56/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6545 - loss: 0.6630 - val_accuracy: 0.8667 - val_loss: 0.5553\n",
            "Epoch 57/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6556 - loss: 0.6628 - val_accuracy: 0.8667 - val_loss: 0.5484\n",
            "Epoch 58/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6514 - loss: 0.6647 - val_accuracy: 0.8667 - val_loss: 0.5418\n",
            "Epoch 59/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6691 - loss: 0.6486 - val_accuracy: 0.8667 - val_loss: 0.5350\n",
            "Epoch 60/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6604 - loss: 0.6418 - val_accuracy: 0.8667 - val_loss: 0.5287\n",
            "Epoch 61/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6448 - loss: 0.6557 - val_accuracy: 0.8667 - val_loss: 0.5235\n",
            "Epoch 62/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7104 - loss: 0.6212 - val_accuracy: 0.8667 - val_loss: 0.5176\n",
            "Epoch 63/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6889 - loss: 0.6321 - val_accuracy: 0.8667 - val_loss: 0.5130\n",
            "Epoch 64/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6854 - loss: 0.6314 - val_accuracy: 0.8667 - val_loss: 0.5086\n",
            "Epoch 65/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7121 - loss: 0.6278 - val_accuracy: 0.8667 - val_loss: 0.5043\n",
            "Epoch 66/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6934 - loss: 0.6347 - val_accuracy: 0.8667 - val_loss: 0.5003\n",
            "Epoch 67/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7100 - loss: 0.6198 - val_accuracy: 0.8667 - val_loss: 0.4958\n",
            "Epoch 68/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7086 - loss: 0.6138 - val_accuracy: 0.8667 - val_loss: 0.4917\n",
            "Epoch 69/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6784 - loss: 0.6141 - val_accuracy: 0.8667 - val_loss: 0.4874\n",
            "Epoch 70/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6940 - loss: 0.6056 - val_accuracy: 0.8667 - val_loss: 0.4825\n",
            "Epoch 71/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7211 - loss: 0.6074 - val_accuracy: 0.8667 - val_loss: 0.4776\n",
            "Epoch 72/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6940 - loss: 0.5960 - val_accuracy: 0.8667 - val_loss: 0.4722\n",
            "Epoch 73/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7284 - loss: 0.5882 - val_accuracy: 0.8667 - val_loss: 0.4667\n",
            "Epoch 74/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7076 - loss: 0.5954 - val_accuracy: 0.8667 - val_loss: 0.4619\n",
            "Epoch 75/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7013 - loss: 0.5755 - val_accuracy: 0.8667 - val_loss: 0.4575\n",
            "Epoch 76/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7211 - loss: 0.5799 - val_accuracy: 0.8667 - val_loss: 0.4530\n",
            "Epoch 77/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7388 - loss: 0.5606 - val_accuracy: 0.8667 - val_loss: 0.4485\n",
            "Epoch 78/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6982 - loss: 0.5815 - val_accuracy: 0.8667 - val_loss: 0.4448\n",
            "Epoch 79/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7104 - loss: 0.5815 - val_accuracy: 0.8667 - val_loss: 0.4410\n",
            "Epoch 80/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7176 - loss: 0.5691 - val_accuracy: 0.8667 - val_loss: 0.4369\n",
            "Epoch 81/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7312 - loss: 0.5750 - val_accuracy: 0.8667 - val_loss: 0.4326\n",
            "Epoch 82/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6926 - loss: 0.5849 - val_accuracy: 0.8667 - val_loss: 0.4284\n",
            "Epoch 83/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7572 - loss: 0.5342 - val_accuracy: 0.8667 - val_loss: 0.4238\n",
            "Epoch 84/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7343 - loss: 0.5558 - val_accuracy: 0.8667 - val_loss: 0.4195\n",
            "Epoch 85/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7229 - loss: 0.5484 - val_accuracy: 0.8667 - val_loss: 0.4153\n",
            "Epoch 86/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7406 - loss: 0.5373 - val_accuracy: 0.8667 - val_loss: 0.4116\n",
            "Epoch 87/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7124 - loss: 0.5637 - val_accuracy: 0.8667 - val_loss: 0.4088\n",
            "Epoch 88/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7124 - loss: 0.5421 - val_accuracy: 0.8667 - val_loss: 0.4050\n",
            "Epoch 89/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7354 - loss: 0.5309 - val_accuracy: 0.8667 - val_loss: 0.4012\n",
            "Epoch 90/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7301 - loss: 0.5349 - val_accuracy: 0.8667 - val_loss: 0.3980\n",
            "Epoch 91/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7093 - loss: 0.5438 - val_accuracy: 0.8667 - val_loss: 0.3957\n",
            "Epoch 92/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7479 - loss: 0.5197 - val_accuracy: 0.8667 - val_loss: 0.3930\n",
            "Epoch 93/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7312 - loss: 0.5496 - val_accuracy: 0.8667 - val_loss: 0.3910\n",
            "Epoch 94/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7451 - loss: 0.5282 - val_accuracy: 0.8667 - val_loss: 0.3898\n",
            "Epoch 95/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7853 - loss: 0.5224 - val_accuracy: 0.8667 - val_loss: 0.3882\n",
            "Epoch 96/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8096 - loss: 0.5231 - val_accuracy: 0.8667 - val_loss: 0.3860\n",
            "Epoch 97/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8009 - loss: 0.5304 - val_accuracy: 0.8667 - val_loss: 0.3830\n",
            "Epoch 98/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7999 - loss: 0.5321 - val_accuracy: 0.8667 - val_loss: 0.3793\n",
            "Epoch 99/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7898 - loss: 0.5214 - val_accuracy: 0.8667 - val_loss: 0.3760\n",
            "Epoch 100/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7912 - loss: 0.5106 - val_accuracy: 0.8667 - val_loss: 0.3737\n",
            "Epoch 101/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8054 - loss: 0.5072 - val_accuracy: 0.8667 - val_loss: 0.3719\n",
            "Epoch 102/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8030 - loss: 0.4996 - val_accuracy: 0.8667 - val_loss: 0.3701\n",
            "Epoch 103/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7988 - loss: 0.5239 - val_accuracy: 0.8667 - val_loss: 0.3684\n",
            "Epoch 104/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8252 - loss: 0.4948 - val_accuracy: 0.8667 - val_loss: 0.3662\n",
            "Epoch 105/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8210 - loss: 0.4925 - val_accuracy: 0.8667 - val_loss: 0.3628\n",
            "Epoch 106/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8033 - loss: 0.5061 - val_accuracy: 0.8667 - val_loss: 0.3602\n",
            "Epoch 107/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8377 - loss: 0.4810 - val_accuracy: 0.8667 - val_loss: 0.3575\n",
            "Epoch 108/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8366 - loss: 0.4941 - val_accuracy: 0.8667 - val_loss: 0.3559\n",
            "Epoch 109/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8179 - loss: 0.4993 - val_accuracy: 0.8667 - val_loss: 0.3546\n",
            "Epoch 110/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8148 - loss: 0.5006 - val_accuracy: 0.8667 - val_loss: 0.3523\n",
            "Epoch 111/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8325 - loss: 0.4740 - val_accuracy: 0.8667 - val_loss: 0.3500\n",
            "Epoch 112/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8262 - loss: 0.4797 - val_accuracy: 0.8667 - val_loss: 0.3479\n",
            "Epoch 113/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8418 - loss: 0.4753 - val_accuracy: 0.8667 - val_loss: 0.3457\n",
            "Epoch 114/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8217 - loss: 0.4790 - val_accuracy: 0.8667 - val_loss: 0.3441\n",
            "Epoch 115/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8446 - loss: 0.4741 - val_accuracy: 0.8667 - val_loss: 0.3429\n",
            "Epoch 116/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8338 - loss: 0.4864 - val_accuracy: 0.9333 - val_loss: 0.3424\n",
            "Epoch 117/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8606 - loss: 0.4515 - val_accuracy: 0.9333 - val_loss: 0.3421\n",
            "Epoch 118/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8738 - loss: 0.4844 - val_accuracy: 0.9333 - val_loss: 0.3410\n",
            "Epoch 119/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8734 - loss: 0.4684 - val_accuracy: 0.9333 - val_loss: 0.3405\n",
            "Epoch 120/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8932 - loss: 0.4474 - val_accuracy: 0.9333 - val_loss: 0.3384\n",
            "Epoch 121/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8671 - loss: 0.4757 - val_accuracy: 0.9333 - val_loss: 0.3367\n",
            "Epoch 122/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8939 - loss: 0.4677 - val_accuracy: 0.9333 - val_loss: 0.3346\n",
            "Epoch 123/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8939 - loss: 0.4692 - val_accuracy: 0.9333 - val_loss: 0.3332\n",
            "Epoch 124/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8730 - loss: 0.4674 - val_accuracy: 0.9333 - val_loss: 0.3315\n",
            "Epoch 125/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8845 - loss: 0.4730 - val_accuracy: 0.9333 - val_loss: 0.3293\n",
            "Epoch 126/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8605 - loss: 0.4670 - val_accuracy: 0.9333 - val_loss: 0.3271\n",
            "Epoch 127/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8838 - loss: 0.4607 - val_accuracy: 0.9333 - val_loss: 0.3243\n",
            "Epoch 128/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8755 - loss: 0.4560 - val_accuracy: 0.9333 - val_loss: 0.3220\n",
            "Epoch 129/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8796 - loss: 0.4523 - val_accuracy: 0.9333 - val_loss: 0.3201\n",
            "Epoch 130/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8807 - loss: 0.4476 - val_accuracy: 0.9333 - val_loss: 0.3187\n",
            "Epoch 131/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8824 - loss: 0.4406 - val_accuracy: 0.9333 - val_loss: 0.3177\n",
            "Epoch 132/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8859 - loss: 0.4434 - val_accuracy: 1.0000 - val_loss: 0.3170\n",
            "Epoch 133/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9223 - loss: 0.4381 - val_accuracy: 1.0000 - val_loss: 0.3166\n",
            "Epoch 134/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9084 - loss: 0.4303 - val_accuracy: 1.0000 - val_loss: 0.3159\n",
            "Epoch 135/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9282 - loss: 0.4192 - val_accuracy: 1.0000 - val_loss: 0.3154\n",
            "Epoch 136/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9483 - loss: 0.4227 - val_accuracy: 1.0000 - val_loss: 0.3155\n",
            "Epoch 137/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9410 - loss: 0.4266 - val_accuracy: 1.0000 - val_loss: 0.3155\n",
            "Epoch 138/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9410 - loss: 0.4268 - val_accuracy: 1.0000 - val_loss: 0.3164\n",
            "Epoch 139/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9244 - loss: 0.4489 - val_accuracy: 1.0000 - val_loss: 0.3154\n",
            "Epoch 140/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.4304 - val_accuracy: 1.0000 - val_loss: 0.3124\n",
            "Epoch 141/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.4278 - val_accuracy: 1.0000 - val_loss: 0.3106\n",
            "Epoch 142/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9285 - loss: 0.4242 - val_accuracy: 1.0000 - val_loss: 0.3101\n",
            "Epoch 143/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9171 - loss: 0.4289 - val_accuracy: 1.0000 - val_loss: 0.3112\n",
            "Epoch 144/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9469 - loss: 0.4152 - val_accuracy: 1.0000 - val_loss: 0.3110\n",
            "Epoch 145/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9365 - loss: 0.4255 - val_accuracy: 1.0000 - val_loss: 0.3106\n",
            "Epoch 146/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9271 - loss: 0.4240 - val_accuracy: 1.0000 - val_loss: 0.3086\n",
            "Epoch 147/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.4115 - val_accuracy: 1.0000 - val_loss: 0.3063\n",
            "Epoch 148/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9365 - loss: 0.4132 - val_accuracy: 1.0000 - val_loss: 0.3037\n",
            "Epoch 149/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9212 - loss: 0.4217 - val_accuracy: 1.0000 - val_loss: 0.3011\n",
            "Epoch 150/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9358 - loss: 0.4085 - val_accuracy: 1.0000 - val_loss: 0.2975\n",
            "Epoch 151/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9275 - loss: 0.4371 - val_accuracy: 1.0000 - val_loss: 0.2959\n",
            "Epoch 152/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9379 - loss: 0.4216 - val_accuracy: 1.0000 - val_loss: 0.2939\n",
            "Epoch 153/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.4030 - val_accuracy: 1.0000 - val_loss: 0.2917\n",
            "Epoch 154/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9244 - loss: 0.4118 - val_accuracy: 1.0000 - val_loss: 0.2922\n",
            "Epoch 155/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9358 - loss: 0.4101 - val_accuracy: 1.0000 - val_loss: 0.2925\n",
            "Epoch 156/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.3903 - val_accuracy: 1.0000 - val_loss: 0.2917\n",
            "Epoch 157/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9459 - loss: 0.3908 - val_accuracy: 1.0000 - val_loss: 0.2900\n",
            "Epoch 158/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9431 - loss: 0.3853 - val_accuracy: 1.0000 - val_loss: 0.2869\n",
            "Epoch 159/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9358 - loss: 0.4019 - val_accuracy: 1.0000 - val_loss: 0.2830\n",
            "Epoch 160/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9306 - loss: 0.3978 - val_accuracy: 1.0000 - val_loss: 0.2808\n",
            "Epoch 161/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9181 - loss: 0.3851 - val_accuracy: 1.0000 - val_loss: 0.2777\n",
            "Epoch 162/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9463 - loss: 0.3955 - val_accuracy: 1.0000 - val_loss: 0.2756\n",
            "Epoch 163/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9244 - loss: 0.4079 - val_accuracy: 1.0000 - val_loss: 0.2748\n",
            "Epoch 164/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9421 - loss: 0.3837 - val_accuracy: 1.0000 - val_loss: 0.2742\n",
            "Epoch 165/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9265 - loss: 0.3799 - val_accuracy: 1.0000 - val_loss: 0.2746\n",
            "Epoch 166/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9275 - loss: 0.3826 - val_accuracy: 1.0000 - val_loss: 0.2733\n",
            "Epoch 167/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9087 - loss: 0.3837 - val_accuracy: 1.0000 - val_loss: 0.2705\n",
            "Epoch 168/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9212 - loss: 0.3982 - val_accuracy: 1.0000 - val_loss: 0.2681\n",
            "Epoch 169/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9275 - loss: 0.3908 - val_accuracy: 1.0000 - val_loss: 0.2665\n",
            "Epoch 170/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9265 - loss: 0.4016 - val_accuracy: 1.0000 - val_loss: 0.2654\n",
            "Epoch 171/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9327 - loss: 0.3789 - val_accuracy: 1.0000 - val_loss: 0.2641\n",
            "Epoch 172/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9306 - loss: 0.3754 - val_accuracy: 1.0000 - val_loss: 0.2631\n",
            "Epoch 173/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9212 - loss: 0.3685 - val_accuracy: 1.0000 - val_loss: 0.2638\n",
            "Epoch 174/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9337 - loss: 0.3830 - val_accuracy: 1.0000 - val_loss: 0.2640\n",
            "Epoch 175/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9285 - loss: 0.3642 - val_accuracy: 1.0000 - val_loss: 0.2635\n",
            "Epoch 176/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9473 - loss: 0.3735 - val_accuracy: 1.0000 - val_loss: 0.2639\n",
            "Epoch 177/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9490 - loss: 0.3794 - val_accuracy: 1.0000 - val_loss: 0.2651\n",
            "Epoch 178/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9691 - loss: 0.3873 - val_accuracy: 1.0000 - val_loss: 0.2638\n",
            "Epoch 179/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9671 - loss: 0.3675 - val_accuracy: 1.0000 - val_loss: 0.2629\n",
            "Epoch 180/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9639 - loss: 0.3668 - val_accuracy: 1.0000 - val_loss: 0.2617\n",
            "Epoch 181/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.3759 - val_accuracy: 1.0000 - val_loss: 0.2600\n",
            "Epoch 182/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9660 - loss: 0.3684 - val_accuracy: 1.0000 - val_loss: 0.2579\n",
            "Epoch 183/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9396 - loss: 0.3529 - val_accuracy: 1.0000 - val_loss: 0.2551\n",
            "Epoch 184/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9303 - loss: 0.3725 - val_accuracy: 1.0000 - val_loss: 0.2521\n",
            "Epoch 185/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9369 - loss: 0.3576 - val_accuracy: 1.0000 - val_loss: 0.2498\n",
            "Epoch 186/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9275 - loss: 0.3637 - val_accuracy: 1.0000 - val_loss: 0.2474\n",
            "Epoch 187/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9369 - loss: 0.3536 - val_accuracy: 1.0000 - val_loss: 0.2445\n",
            "Epoch 188/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9358 - loss: 0.3538 - val_accuracy: 1.0000 - val_loss: 0.2431\n",
            "Epoch 189/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9358 - loss: 0.3594 - val_accuracy: 1.0000 - val_loss: 0.2430\n",
            "Epoch 190/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9150 - loss: 0.3655 - val_accuracy: 1.0000 - val_loss: 0.2431\n",
            "Epoch 191/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9327 - loss: 0.3513 - val_accuracy: 1.0000 - val_loss: 0.2424\n",
            "Epoch 192/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9431 - loss: 0.3314 - val_accuracy: 1.0000 - val_loss: 0.2419\n",
            "Epoch 193/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9473 - loss: 0.3564 - val_accuracy: 1.0000 - val_loss: 0.2416\n",
            "Epoch 194/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.3383 - val_accuracy: 1.0000 - val_loss: 0.2419\n",
            "Epoch 195/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9449 - loss: 0.3459 - val_accuracy: 1.0000 - val_loss: 0.2433\n",
            "Epoch 196/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9639 - loss: 0.3351 - val_accuracy: 1.0000 - val_loss: 0.2441\n",
            "Epoch 197/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9452 - loss: 0.3493 - val_accuracy: 1.0000 - val_loss: 0.2432\n",
            "Epoch 198/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.3438 - val_accuracy: 1.0000 - val_loss: 0.2409\n",
            "Epoch 199/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.3404 - val_accuracy: 1.0000 - val_loss: 0.2397\n",
            "Epoch 200/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9712 - loss: 0.3154 - val_accuracy: 1.0000 - val_loss: 0.2368\n",
            "Epoch 201/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9549 - loss: 0.3399 - val_accuracy: 1.0000 - val_loss: 0.2349\n",
            "Epoch 202/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9549 - loss: 0.3495 - val_accuracy: 1.0000 - val_loss: 0.2340\n",
            "Epoch 203/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9549 - loss: 0.3129 - val_accuracy: 1.0000 - val_loss: 0.2325\n",
            "Epoch 204/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.3334 - val_accuracy: 1.0000 - val_loss: 0.2320\n",
            "Epoch 205/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.3315 - val_accuracy: 1.0000 - val_loss: 0.2333\n",
            "Epoch 206/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9514 - loss: 0.3360 - val_accuracy: 1.0000 - val_loss: 0.2326\n",
            "Epoch 207/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9546 - loss: 0.3251 - val_accuracy: 1.0000 - val_loss: 0.2322\n",
            "Epoch 208/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9671 - loss: 0.3190 - val_accuracy: 1.0000 - val_loss: 0.2327\n",
            "Epoch 209/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9754 - loss: 0.3089 - val_accuracy: 1.0000 - val_loss: 0.2320\n",
            "Epoch 210/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9712 - loss: 0.3094 - val_accuracy: 1.0000 - val_loss: 0.2314\n",
            "Epoch 211/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.3292 - val_accuracy: 1.0000 - val_loss: 0.2320\n",
            "Epoch 212/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9750 - loss: 0.3221 - val_accuracy: 1.0000 - val_loss: 0.2321\n",
            "Epoch 213/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9698 - loss: 0.3128 - val_accuracy: 1.0000 - val_loss: 0.2314\n",
            "Epoch 214/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9761 - loss: 0.3249 - val_accuracy: 1.0000 - val_loss: 0.2297\n",
            "Epoch 215/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9733 - loss: 0.3133 - val_accuracy: 1.0000 - val_loss: 0.2283\n",
            "Epoch 216/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.3269 - val_accuracy: 1.0000 - val_loss: 0.2291\n",
            "Epoch 217/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9604 - loss: 0.3234 - val_accuracy: 1.0000 - val_loss: 0.2283\n",
            "Epoch 218/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9698 - loss: 0.3051 - val_accuracy: 1.0000 - val_loss: 0.2263\n",
            "Epoch 219/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9719 - loss: 0.3054 - val_accuracy: 1.0000 - val_loss: 0.2236\n",
            "Epoch 220/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9733 - loss: 0.3119 - val_accuracy: 1.0000 - val_loss: 0.2206\n",
            "Epoch 221/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9514 - loss: 0.3124 - val_accuracy: 1.0000 - val_loss: 0.2195\n",
            "Epoch 222/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.3041 - val_accuracy: 1.0000 - val_loss: 0.2188\n",
            "Epoch 223/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9723 - loss: 0.3097 - val_accuracy: 1.0000 - val_loss: 0.2182\n",
            "Epoch 224/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.3085 - val_accuracy: 1.0000 - val_loss: 0.2181\n",
            "Epoch 225/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9691 - loss: 0.3056 - val_accuracy: 1.0000 - val_loss: 0.2181\n",
            "Epoch 226/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9844 - loss: 0.3006 - val_accuracy: 1.0000 - val_loss: 0.2193\n",
            "Epoch 227/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9750 - loss: 0.3100 - val_accuracy: 1.0000 - val_loss: 0.2202\n",
            "Epoch 228/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9750 - loss: 0.3016 - val_accuracy: 1.0000 - val_loss: 0.2194\n",
            "Epoch 229/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9813 - loss: 0.3001 - val_accuracy: 1.0000 - val_loss: 0.2174\n",
            "Epoch 230/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.3014 - val_accuracy: 1.0000 - val_loss: 0.2151\n",
            "Epoch 231/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9792 - loss: 0.3038 - val_accuracy: 1.0000 - val_loss: 0.2121\n",
            "Epoch 232/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9577 - loss: 0.2986 - val_accuracy: 1.0000 - val_loss: 0.2093\n",
            "Epoch 233/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9452 - loss: 0.2990 - val_accuracy: 1.0000 - val_loss: 0.2060\n",
            "Epoch 234/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.3133 - val_accuracy: 1.0000 - val_loss: 0.2035\n",
            "Epoch 235/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9671 - loss: 0.2976 - val_accuracy: 1.0000 - val_loss: 0.2019\n",
            "Epoch 236/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9608 - loss: 0.2982 - val_accuracy: 1.0000 - val_loss: 0.2014\n",
            "Epoch 237/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.3044 - val_accuracy: 1.0000 - val_loss: 0.2021\n",
            "Epoch 238/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.3005 - val_accuracy: 1.0000 - val_loss: 0.2028\n",
            "Epoch 239/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9452 - loss: 0.3029 - val_accuracy: 1.0000 - val_loss: 0.2039\n",
            "Epoch 240/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9671 - loss: 0.2874 - val_accuracy: 1.0000 - val_loss: 0.2049\n",
            "Epoch 241/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9771 - loss: 0.2712 - val_accuracy: 1.0000 - val_loss: 0.2052\n",
            "Epoch 242/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9636 - loss: 0.2816 - val_accuracy: 1.0000 - val_loss: 0.2058\n",
            "Epoch 243/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9729 - loss: 0.2833 - val_accuracy: 1.0000 - val_loss: 0.2064\n",
            "Epoch 244/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9604 - loss: 0.2877 - val_accuracy: 1.0000 - val_loss: 0.2046\n",
            "Epoch 245/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9667 - loss: 0.2920 - val_accuracy: 1.0000 - val_loss: 0.2019\n",
            "Epoch 246/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9729 - loss: 0.2827 - val_accuracy: 1.0000 - val_loss: 0.1996\n",
            "Epoch 247/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9761 - loss: 0.2816 - val_accuracy: 1.0000 - val_loss: 0.1972\n",
            "Epoch 248/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.2681 - val_accuracy: 1.0000 - val_loss: 0.1958\n",
            "Epoch 249/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.2695 - val_accuracy: 1.0000 - val_loss: 0.1950\n",
            "Epoch 250/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9733 - loss: 0.2746 - val_accuracy: 1.0000 - val_loss: 0.1943\n",
            "Epoch 251/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9723 - loss: 0.2706 - val_accuracy: 1.0000 - val_loss: 0.1930\n",
            "Epoch 252/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9608 - loss: 0.2767 - val_accuracy: 1.0000 - val_loss: 0.1919\n",
            "Epoch 253/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9639 - loss: 0.2759 - val_accuracy: 1.0000 - val_loss: 0.1901\n",
            "Epoch 254/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9639 - loss: 0.2743 - val_accuracy: 1.0000 - val_loss: 0.1895\n",
            "Epoch 255/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9639 - loss: 0.2756 - val_accuracy: 1.0000 - val_loss: 0.1895\n",
            "Epoch 256/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9504 - loss: 0.2691 - val_accuracy: 1.0000 - val_loss: 0.1893\n",
            "Epoch 257/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9452 - loss: 0.2828 - val_accuracy: 1.0000 - val_loss: 0.1891\n",
            "Epoch 258/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9608 - loss: 0.2658 - val_accuracy: 1.0000 - val_loss: 0.1882\n",
            "Epoch 259/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9702 - loss: 0.2689 - val_accuracy: 1.0000 - val_loss: 0.1863\n",
            "Epoch 260/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9514 - loss: 0.2614 - val_accuracy: 1.0000 - val_loss: 0.1859\n",
            "Epoch 261/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9639 - loss: 0.2584 - val_accuracy: 1.0000 - val_loss: 0.1832\n",
            "Epoch 262/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9639 - loss: 0.2766 - val_accuracy: 1.0000 - val_loss: 0.1827\n",
            "Epoch 263/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9546 - loss: 0.2655 - val_accuracy: 1.0000 - val_loss: 0.1826\n",
            "Epoch 264/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9566 - loss: 0.2661 - val_accuracy: 1.0000 - val_loss: 0.1858\n",
            "Epoch 265/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9785 - loss: 0.2528 - val_accuracy: 1.0000 - val_loss: 0.1881\n",
            "Epoch 266/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9546 - loss: 0.2592 - val_accuracy: 1.0000 - val_loss: 0.1870\n",
            "Epoch 267/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9577 - loss: 0.2514 - val_accuracy: 1.0000 - val_loss: 0.1856\n",
            "Epoch 268/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9608 - loss: 0.2537 - val_accuracy: 1.0000 - val_loss: 0.1840\n",
            "Epoch 269/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9667 - loss: 0.2663 - val_accuracy: 1.0000 - val_loss: 0.1819\n",
            "Epoch 270/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9698 - loss: 0.2507 - val_accuracy: 1.0000 - val_loss: 0.1798\n",
            "Epoch 271/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9542 - loss: 0.2577 - val_accuracy: 1.0000 - val_loss: 0.1782\n",
            "Epoch 272/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9546 - loss: 0.2624 - val_accuracy: 1.0000 - val_loss: 0.1755\n",
            "Epoch 273/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9577 - loss: 0.2637 - val_accuracy: 1.0000 - val_loss: 0.1742\n",
            "Epoch 274/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.2455 - val_accuracy: 1.0000 - val_loss: 0.1732\n",
            "Epoch 275/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9764 - loss: 0.2326 - val_accuracy: 1.0000 - val_loss: 0.1723\n",
            "Epoch 276/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.2482 - val_accuracy: 1.0000 - val_loss: 0.1732\n",
            "Epoch 277/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9698 - loss: 0.2509 - val_accuracy: 1.0000 - val_loss: 0.1741\n",
            "Epoch 278/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9667 - loss: 0.2434 - val_accuracy: 1.0000 - val_loss: 0.1753\n",
            "Epoch 279/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9667 - loss: 0.2509 - val_accuracy: 1.0000 - val_loss: 0.1759\n",
            "Epoch 280/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.2597 - val_accuracy: 1.0000 - val_loss: 0.1773\n",
            "Epoch 281/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9577 - loss: 0.2434 - val_accuracy: 1.0000 - val_loss: 0.1776\n",
            "Epoch 282/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9671 - loss: 0.2406 - val_accuracy: 1.0000 - val_loss: 0.1792\n",
            "Epoch 283/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9483 - loss: 0.2436 - val_accuracy: 1.0000 - val_loss: 0.1764\n",
            "Epoch 284/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.2438 - val_accuracy: 1.0000 - val_loss: 0.1731\n",
            "Epoch 285/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9598 - loss: 0.2385 - val_accuracy: 1.0000 - val_loss: 0.1686\n",
            "Epoch 286/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.2223 - val_accuracy: 1.0000 - val_loss: 0.1655\n",
            "Epoch 287/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.2504 - val_accuracy: 1.0000 - val_loss: 0.1647\n",
            "Epoch 288/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2607 - val_accuracy: 1.0000 - val_loss: 0.1636\n",
            "Epoch 289/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9483 - loss: 0.2582 - val_accuracy: 1.0000 - val_loss: 0.1631\n",
            "Epoch 290/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9577 - loss: 0.2428 - val_accuracy: 1.0000 - val_loss: 0.1620\n",
            "Epoch 291/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9702 - loss: 0.2420 - val_accuracy: 1.0000 - val_loss: 0.1605\n",
            "Epoch 292/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2450 - val_accuracy: 1.0000 - val_loss: 0.1596\n",
            "Epoch 293/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.2391 - val_accuracy: 1.0000 - val_loss: 0.1580\n",
            "Epoch 294/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.2277 - val_accuracy: 1.0000 - val_loss: 0.1570\n",
            "Epoch 295/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.2328 - val_accuracy: 1.0000 - val_loss: 0.1566\n",
            "Epoch 296/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2372 - val_accuracy: 1.0000 - val_loss: 0.1555\n",
            "Epoch 297/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.2425 - val_accuracy: 1.0000 - val_loss: 0.1547\n",
            "Epoch 298/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9598 - loss: 0.2378 - val_accuracy: 1.0000 - val_loss: 0.1542\n",
            "Epoch 299/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9629 - loss: 0.2389 - val_accuracy: 1.0000 - val_loss: 0.1555\n",
            "Epoch 300/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9785 - loss: 0.2194 - val_accuracy: 1.0000 - val_loss: 0.1576\n",
            "Epoch 301/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.2233 - val_accuracy: 1.0000 - val_loss: 0.1603\n",
            "Epoch 302/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.2420 - val_accuracy: 1.0000 - val_loss: 0.1620\n",
            "Epoch 303/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9702 - loss: 0.2097 - val_accuracy: 1.0000 - val_loss: 0.1627\n",
            "Epoch 304/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9577 - loss: 0.2168 - val_accuracy: 1.0000 - val_loss: 0.1613\n",
            "Epoch 305/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9754 - loss: 0.2123 - val_accuracy: 1.0000 - val_loss: 0.1592\n",
            "Epoch 306/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.2256 - val_accuracy: 1.0000 - val_loss: 0.1595\n",
            "Epoch 307/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2312 - val_accuracy: 1.0000 - val_loss: 0.1580\n",
            "Epoch 308/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9754 - loss: 0.2166 - val_accuracy: 1.0000 - val_loss: 0.1551\n",
            "Epoch 309/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.2160 - val_accuracy: 1.0000 - val_loss: 0.1541\n",
            "Epoch 310/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.2223 - val_accuracy: 1.0000 - val_loss: 0.1551\n",
            "Epoch 311/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9691 - loss: 0.2124 - val_accuracy: 1.0000 - val_loss: 0.1561\n",
            "Epoch 312/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.2179 - val_accuracy: 1.0000 - val_loss: 0.1568\n",
            "Epoch 313/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9723 - loss: 0.2034 - val_accuracy: 1.0000 - val_loss: 0.1552\n",
            "Epoch 314/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2188 - val_accuracy: 1.0000 - val_loss: 0.1534\n",
            "Epoch 315/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.2304 - val_accuracy: 1.0000 - val_loss: 0.1514\n",
            "Epoch 316/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.2208 - val_accuracy: 1.0000 - val_loss: 0.1498\n",
            "Epoch 317/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9566 - loss: 0.2209 - val_accuracy: 1.0000 - val_loss: 0.1489\n",
            "Epoch 318/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9514 - loss: 0.2125 - val_accuracy: 1.0000 - val_loss: 0.1463\n",
            "Epoch 319/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9702 - loss: 0.2088 - val_accuracy: 1.0000 - val_loss: 0.1443\n",
            "Epoch 320/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.1946 - val_accuracy: 1.0000 - val_loss: 0.1432\n",
            "Epoch 321/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.2084 - val_accuracy: 1.0000 - val_loss: 0.1439\n",
            "Epoch 322/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9629 - loss: 0.2080 - val_accuracy: 1.0000 - val_loss: 0.1443\n",
            "Epoch 323/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9542 - loss: 0.2208 - val_accuracy: 1.0000 - val_loss: 0.1453\n",
            "Epoch 324/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9608 - loss: 0.2045 - val_accuracy: 1.0000 - val_loss: 0.1452\n",
            "Epoch 325/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9698 - loss: 0.2063 - val_accuracy: 1.0000 - val_loss: 0.1439\n",
            "Epoch 326/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9671 - loss: 0.1958 - val_accuracy: 1.0000 - val_loss: 0.1447\n",
            "Epoch 327/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.2110 - val_accuracy: 1.0000 - val_loss: 0.1478\n",
            "Epoch 328/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.2163 - val_accuracy: 1.0000 - val_loss: 0.1490\n",
            "Epoch 329/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.2161 - val_accuracy: 1.0000 - val_loss: 0.1476\n",
            "Epoch 330/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.2110 - val_accuracy: 1.0000 - val_loss: 0.1454\n",
            "Epoch 331/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9608 - loss: 0.1927 - val_accuracy: 1.0000 - val_loss: 0.1434\n",
            "Epoch 332/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9608 - loss: 0.2094 - val_accuracy: 1.0000 - val_loss: 0.1418\n",
            "Epoch 333/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.2029 - val_accuracy: 1.0000 - val_loss: 0.1401\n",
            "Epoch 334/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.1963 - val_accuracy: 1.0000 - val_loss: 0.1395\n",
            "Epoch 335/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.2073 - val_accuracy: 1.0000 - val_loss: 0.1413\n",
            "Epoch 336/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1976 - val_accuracy: 1.0000 - val_loss: 0.1420\n",
            "Epoch 337/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.1967 - val_accuracy: 1.0000 - val_loss: 0.1404\n",
            "Epoch 338/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9483 - loss: 0.2168 - val_accuracy: 1.0000 - val_loss: 0.1372\n",
            "Epoch 339/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9733 - loss: 0.1912 - val_accuracy: 1.0000 - val_loss: 0.1353\n",
            "Epoch 340/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9761 - loss: 0.1905 - val_accuracy: 1.0000 - val_loss: 0.1348\n",
            "Epoch 341/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9754 - loss: 0.1955 - val_accuracy: 1.0000 - val_loss: 0.1357\n",
            "Epoch 342/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.1931 - val_accuracy: 1.0000 - val_loss: 0.1359\n",
            "Epoch 343/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.1931 - val_accuracy: 1.0000 - val_loss: 0.1357\n",
            "Epoch 344/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.1833 - val_accuracy: 1.0000 - val_loss: 0.1352\n",
            "Epoch 345/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9546 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 0.1341\n",
            "Epoch 346/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9608 - loss: 0.1934 - val_accuracy: 1.0000 - val_loss: 0.1326\n",
            "Epoch 347/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9546 - loss: 0.1957 - val_accuracy: 1.0000 - val_loss: 0.1340\n",
            "Epoch 348/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.2068 - val_accuracy: 1.0000 - val_loss: 0.1350\n",
            "Epoch 349/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9806 - loss: 0.1821 - val_accuracy: 1.0000 - val_loss: 0.1345\n",
            "Epoch 350/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1961 - val_accuracy: 1.0000 - val_loss: 0.1333\n",
            "Epoch 351/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.1902 - val_accuracy: 1.0000 - val_loss: 0.1315\n",
            "Epoch 352/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9577 - loss: 0.1917 - val_accuracy: 1.0000 - val_loss: 0.1330\n",
            "Epoch 353/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9546 - loss: 0.1862 - val_accuracy: 1.0000 - val_loss: 0.1340\n",
            "Epoch 354/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.1886 - val_accuracy: 1.0000 - val_loss: 0.1323\n",
            "Epoch 355/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9452 - loss: 0.1980 - val_accuracy: 1.0000 - val_loss: 0.1302\n",
            "Epoch 356/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.1902 - val_accuracy: 1.0000 - val_loss: 0.1287\n",
            "Epoch 357/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1853 - val_accuracy: 1.0000 - val_loss: 0.1283\n",
            "Epoch 358/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9577 - loss: 0.1767 - val_accuracy: 1.0000 - val_loss: 0.1291\n",
            "Epoch 359/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9389 - loss: 0.2166 - val_accuracy: 1.0000 - val_loss: 0.1293\n",
            "Epoch 360/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9639 - loss: 0.1796 - val_accuracy: 1.0000 - val_loss: 0.1287\n",
            "Epoch 361/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9723 - loss: 0.1822 - val_accuracy: 1.0000 - val_loss: 0.1272\n",
            "Epoch 362/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9639 - loss: 0.1784 - val_accuracy: 1.0000 - val_loss: 0.1263\n",
            "Epoch 363/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9639 - loss: 0.1862 - val_accuracy: 1.0000 - val_loss: 0.1257\n",
            "Epoch 364/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9671 - loss: 0.1774 - val_accuracy: 1.0000 - val_loss: 0.1250\n",
            "Epoch 365/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9639 - loss: 0.1762 - val_accuracy: 1.0000 - val_loss: 0.1241\n",
            "Epoch 366/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9639 - loss: 0.1752 - val_accuracy: 1.0000 - val_loss: 0.1233\n",
            "Epoch 367/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9702 - loss: 0.1654 - val_accuracy: 1.0000 - val_loss: 0.1240\n",
            "Epoch 368/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9608 - loss: 0.1953 - val_accuracy: 1.0000 - val_loss: 0.1241\n",
            "Epoch 369/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.1934 - val_accuracy: 1.0000 - val_loss: 0.1243\n",
            "Epoch 370/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9598 - loss: 0.1854 - val_accuracy: 1.0000 - val_loss: 0.1248\n",
            "Epoch 371/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.1779 - val_accuracy: 1.0000 - val_loss: 0.1250\n",
            "Epoch 372/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.1805 - val_accuracy: 1.0000 - val_loss: 0.1253\n",
            "Epoch 373/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9514 - loss: 0.1883 - val_accuracy: 1.0000 - val_loss: 0.1238\n",
            "Epoch 374/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9691 - loss: 0.1699 - val_accuracy: 1.0000 - val_loss: 0.1224\n",
            "Epoch 375/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.1734 - val_accuracy: 1.0000 - val_loss: 0.1230\n",
            "Epoch 376/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9598 - loss: 0.1697 - val_accuracy: 1.0000 - val_loss: 0.1229\n",
            "Epoch 377/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9577 - loss: 0.1919 - val_accuracy: 1.0000 - val_loss: 0.1213\n",
            "Epoch 378/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.1644 - val_accuracy: 1.0000 - val_loss: 0.1205\n",
            "Epoch 379/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.1796 - val_accuracy: 1.0000 - val_loss: 0.1204\n",
            "Epoch 380/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.1846 - val_accuracy: 1.0000 - val_loss: 0.1211\n",
            "Epoch 381/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9702 - loss: 0.1638 - val_accuracy: 1.0000 - val_loss: 0.1206\n",
            "Epoch 382/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9691 - loss: 0.1718 - val_accuracy: 1.0000 - val_loss: 0.1197\n",
            "Epoch 383/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9723 - loss: 0.1676 - val_accuracy: 1.0000 - val_loss: 0.1204\n",
            "Epoch 384/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9504 - loss: 0.1791 - val_accuracy: 1.0000 - val_loss: 0.1195\n",
            "Epoch 385/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.1801 - val_accuracy: 1.0000 - val_loss: 0.1185\n",
            "Epoch 386/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9639 - loss: 0.1699 - val_accuracy: 1.0000 - val_loss: 0.1169\n",
            "Epoch 387/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9546 - loss: 0.1892 - val_accuracy: 1.0000 - val_loss: 0.1149\n",
            "Epoch 388/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9702 - loss: 0.1678 - val_accuracy: 1.0000 - val_loss: 0.1137\n",
            "Epoch 389/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9601 - loss: 0.1542 - val_accuracy: 1.0000 - val_loss: 0.1124\n",
            "Epoch 390/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9764 - loss: 0.1636 - val_accuracy: 1.0000 - val_loss: 0.1145\n",
            "Epoch 391/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9639 - loss: 0.1811 - val_accuracy: 1.0000 - val_loss: 0.1164\n",
            "Epoch 392/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9723 - loss: 0.1661 - val_accuracy: 1.0000 - val_loss: 0.1170\n",
            "Epoch 393/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1824 - val_accuracy: 1.0000 - val_loss: 0.1174\n",
            "Epoch 394/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9514 - loss: 0.1730 - val_accuracy: 1.0000 - val_loss: 0.1180\n",
            "Epoch 395/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9598 - loss: 0.1705 - val_accuracy: 1.0000 - val_loss: 0.1175\n",
            "Epoch 396/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1585 - val_accuracy: 1.0000 - val_loss: 0.1191\n",
            "Epoch 397/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9764 - loss: 0.1588 - val_accuracy: 1.0000 - val_loss: 0.1198\n",
            "Epoch 398/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9671 - loss: 0.1644 - val_accuracy: 1.0000 - val_loss: 0.1178\n",
            "Epoch 399/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9702 - loss: 0.1630 - val_accuracy: 1.0000 - val_loss: 0.1162\n",
            "Epoch 400/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9754 - loss: 0.1541 - val_accuracy: 1.0000 - val_loss: 0.1134\n",
            "Epoch 401/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9483 - loss: 0.1739 - val_accuracy: 1.0000 - val_loss: 0.1126\n",
            "Epoch 402/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.1578 - val_accuracy: 1.0000 - val_loss: 0.1111\n",
            "Epoch 403/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.1504 - val_accuracy: 1.0000 - val_loss: 0.1113\n",
            "Epoch 404/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9577 - loss: 0.1645 - val_accuracy: 1.0000 - val_loss: 0.1125\n",
            "Epoch 405/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9608 - loss: 0.1722 - val_accuracy: 1.0000 - val_loss: 0.1132\n",
            "Epoch 406/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9702 - loss: 0.1596 - val_accuracy: 1.0000 - val_loss: 0.1136\n",
            "Epoch 407/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9608 - loss: 0.1592 - val_accuracy: 1.0000 - val_loss: 0.1131\n",
            "Epoch 408/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9702 - loss: 0.1526 - val_accuracy: 1.0000 - val_loss: 0.1128\n",
            "Epoch 409/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.1717 - val_accuracy: 1.0000 - val_loss: 0.1116\n",
            "Epoch 410/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9546 - loss: 0.1716 - val_accuracy: 1.0000 - val_loss: 0.1101\n",
            "Epoch 411/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9629 - loss: 0.1649 - val_accuracy: 1.0000 - val_loss: 0.1092\n",
            "Epoch 412/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9514 - loss: 0.1558 - val_accuracy: 1.0000 - val_loss: 0.1066\n",
            "Epoch 413/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9775 - loss: 0.1458 - val_accuracy: 1.0000 - val_loss: 0.1053\n",
            "Epoch 414/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9785 - loss: 0.1577 - val_accuracy: 1.0000 - val_loss: 0.1043\n",
            "Epoch 415/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.1593 - val_accuracy: 1.0000 - val_loss: 0.1045\n",
            "Epoch 416/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9608 - loss: 0.1559 - val_accuracy: 1.0000 - val_loss: 0.1055\n",
            "Epoch 417/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9712 - loss: 0.1535 - val_accuracy: 1.0000 - val_loss: 0.1053\n",
            "Epoch 418/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9702 - loss: 0.1566 - val_accuracy: 1.0000 - val_loss: 0.1048\n",
            "Epoch 419/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9514 - loss: 0.1752 - val_accuracy: 1.0000 - val_loss: 0.1036\n",
            "Epoch 420/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9566 - loss: 0.1656 - val_accuracy: 1.0000 - val_loss: 0.1031\n",
            "Epoch 421/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9681 - loss: 0.1576 - val_accuracy: 1.0000 - val_loss: 0.1030\n",
            "Epoch 422/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1506 - val_accuracy: 1.0000 - val_loss: 0.1052\n",
            "Epoch 423/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9577 - loss: 0.1669 - val_accuracy: 1.0000 - val_loss: 0.1062\n",
            "Epoch 424/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.1567 - val_accuracy: 1.0000 - val_loss: 0.1063\n",
            "Epoch 425/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.1672 - val_accuracy: 1.0000 - val_loss: 0.1067\n",
            "Epoch 426/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.1616 - val_accuracy: 1.0000 - val_loss: 0.1063\n",
            "Epoch 427/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.1583 - val_accuracy: 1.0000 - val_loss: 0.1045\n",
            "Epoch 428/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9577 - loss: 0.1574 - val_accuracy: 1.0000 - val_loss: 0.1021\n",
            "Epoch 429/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9514 - loss: 0.1512 - val_accuracy: 1.0000 - val_loss: 0.0996\n",
            "Epoch 430/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1620 - val_accuracy: 1.0000 - val_loss: 0.0985\n",
            "Epoch 431/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9528 - loss: 0.1567 - val_accuracy: 1.0000 - val_loss: 0.0975\n",
            "Epoch 432/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9362 - loss: 0.1675 - val_accuracy: 1.0000 - val_loss: 0.0972\n",
            "Epoch 433/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9299 - loss: 0.1687 - val_accuracy: 1.0000 - val_loss: 0.0980\n",
            "Epoch 434/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9577 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 0.0983\n",
            "Epoch 435/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1570 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
            "Epoch 436/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9598 - loss: 0.1614 - val_accuracy: 1.0000 - val_loss: 0.1026\n",
            "Epoch 437/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9671 - loss: 0.1443 - val_accuracy: 1.0000 - val_loss: 0.1047\n",
            "Epoch 438/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.1629 - val_accuracy: 1.0000 - val_loss: 0.1059\n",
            "Epoch 439/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9639 - loss: 0.1489 - val_accuracy: 1.0000 - val_loss: 0.1044\n",
            "Epoch 440/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1533 - val_accuracy: 1.0000 - val_loss: 0.1034\n",
            "Epoch 441/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9546 - loss: 0.1541 - val_accuracy: 1.0000 - val_loss: 0.1027\n",
            "Epoch 442/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.1610 - val_accuracy: 1.0000 - val_loss: 0.1034\n",
            "Epoch 443/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9608 - loss: 0.1427 - val_accuracy: 1.0000 - val_loss: 0.1030\n",
            "Epoch 444/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9671 - loss: 0.1444 - val_accuracy: 1.0000 - val_loss: 0.1010\n",
            "Epoch 445/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9723 - loss: 0.1355 - val_accuracy: 1.0000 - val_loss: 0.0999\n",
            "Epoch 446/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9723 - loss: 0.1423 - val_accuracy: 1.0000 - val_loss: 0.0996\n",
            "Epoch 447/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9546 - loss: 0.1542 - val_accuracy: 1.0000 - val_loss: 0.0975\n",
            "Epoch 448/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1450 - val_accuracy: 1.0000 - val_loss: 0.0953\n",
            "Epoch 449/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9671 - loss: 0.1370 - val_accuracy: 1.0000 - val_loss: 0.0930\n",
            "Epoch 450/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9455 - loss: 0.1598 - val_accuracy: 1.0000 - val_loss: 0.0919\n",
            "Epoch 451/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9507 - loss: 0.1442 - val_accuracy: 1.0000 - val_loss: 0.0924\n",
            "Epoch 452/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.1452 - val_accuracy: 1.0000 - val_loss: 0.0933\n",
            "Epoch 453/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9546 - loss: 0.1385 - val_accuracy: 1.0000 - val_loss: 0.0948\n",
            "Epoch 454/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9577 - loss: 0.1492 - val_accuracy: 1.0000 - val_loss: 0.0948\n",
            "Epoch 455/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9546 - loss: 0.1510 - val_accuracy: 1.0000 - val_loss: 0.0935\n",
            "Epoch 456/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9671 - loss: 0.1392 - val_accuracy: 1.0000 - val_loss: 0.0927\n",
            "Epoch 457/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9577 - loss: 0.1454 - val_accuracy: 1.0000 - val_loss: 0.0928\n",
            "Epoch 458/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9452 - loss: 0.1481 - val_accuracy: 1.0000 - val_loss: 0.0926\n",
            "Epoch 459/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9608 - loss: 0.1457 - val_accuracy: 1.0000 - val_loss: 0.0916\n",
            "Epoch 460/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9671 - loss: 0.1481 - val_accuracy: 1.0000 - val_loss: 0.0909\n",
            "Epoch 461/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9608 - loss: 0.1453 - val_accuracy: 1.0000 - val_loss: 0.0920\n",
            "Epoch 462/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9452 - loss: 0.1519 - val_accuracy: 1.0000 - val_loss: 0.0933\n",
            "Epoch 463/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9546 - loss: 0.1484 - val_accuracy: 1.0000 - val_loss: 0.0936\n",
            "Epoch 464/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9775 - loss: 0.1328 - val_accuracy: 1.0000 - val_loss: 0.0941\n",
            "Epoch 465/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.1350 - val_accuracy: 1.0000 - val_loss: 0.0937\n",
            "Epoch 466/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.1315 - val_accuracy: 1.0000 - val_loss: 0.0931\n",
            "Epoch 467/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.1480 - val_accuracy: 1.0000 - val_loss: 0.0924\n",
            "Epoch 468/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9639 - loss: 0.1440 - val_accuracy: 1.0000 - val_loss: 0.0912\n",
            "Epoch 469/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1395 - val_accuracy: 1.0000 - val_loss: 0.0898\n",
            "Epoch 470/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.1491 - val_accuracy: 1.0000 - val_loss: 0.0896\n",
            "Epoch 471/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9546 - loss: 0.1496 - val_accuracy: 1.0000 - val_loss: 0.0886\n",
            "Epoch 472/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9671 - loss: 0.1390 - val_accuracy: 1.0000 - val_loss: 0.0867\n",
            "Epoch 473/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9549 - loss: 0.1371 - val_accuracy: 1.0000 - val_loss: 0.0858\n",
            "Epoch 474/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9549 - loss: 0.1444 - val_accuracy: 1.0000 - val_loss: 0.0860\n",
            "Epoch 475/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9487 - loss: 0.1414 - val_accuracy: 1.0000 - val_loss: 0.0859\n",
            "Epoch 476/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.1264 - val_accuracy: 1.0000 - val_loss: 0.0871\n",
            "Epoch 477/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1263 - val_accuracy: 1.0000 - val_loss: 0.0883\n",
            "Epoch 478/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.1393 - val_accuracy: 1.0000 - val_loss: 0.0887\n",
            "Epoch 479/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1356 - val_accuracy: 1.0000 - val_loss: 0.0892\n",
            "Epoch 480/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.1376 - val_accuracy: 1.0000 - val_loss: 0.0889\n",
            "Epoch 481/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9723 - loss: 0.1288 - val_accuracy: 1.0000 - val_loss: 0.0889\n",
            "Epoch 482/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9608 - loss: 0.1399 - val_accuracy: 1.0000 - val_loss: 0.0901\n",
            "Epoch 483/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9608 - loss: 0.1363 - val_accuracy: 1.0000 - val_loss: 0.0911\n",
            "Epoch 484/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9754 - loss: 0.1269 - val_accuracy: 1.0000 - val_loss: 0.0913\n",
            "Epoch 485/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9577 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.0901\n",
            "Epoch 486/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9608 - loss: 0.1382 - val_accuracy: 1.0000 - val_loss: 0.0880\n",
            "Epoch 487/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9608 - loss: 0.1420 - val_accuracy: 1.0000 - val_loss: 0.0857\n",
            "Epoch 488/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9514 - loss: 0.1355 - val_accuracy: 1.0000 - val_loss: 0.0836\n",
            "Epoch 489/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9455 - loss: 0.1454 - val_accuracy: 1.0000 - val_loss: 0.0821\n",
            "Epoch 490/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9237 - loss: 0.1594 - val_accuracy: 1.0000 - val_loss: 0.0827\n",
            "Epoch 491/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9514 - loss: 0.1367 - val_accuracy: 1.0000 - val_loss: 0.0836\n",
            "Epoch 492/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9546 - loss: 0.1435 - val_accuracy: 1.0000 - val_loss: 0.0838\n",
            "Epoch 493/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9733 - loss: 0.1271 - val_accuracy: 1.0000 - val_loss: 0.0842\n",
            "Epoch 494/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9733 - loss: 0.1175 - val_accuracy: 1.0000 - val_loss: 0.0842\n",
            "Epoch 495/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9723 - loss: 0.1288 - val_accuracy: 1.0000 - val_loss: 0.0841\n",
            "Epoch 496/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9546 - loss: 0.1391 - val_accuracy: 1.0000 - val_loss: 0.0839\n",
            "Epoch 497/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9723 - loss: 0.1244 - val_accuracy: 1.0000 - val_loss: 0.0842\n",
            "Epoch 498/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9702 - loss: 0.1303 - val_accuracy: 1.0000 - val_loss: 0.0843\n",
            "Epoch 499/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9514 - loss: 0.1397 - val_accuracy: 1.0000 - val_loss: 0.0856\n",
            "Epoch 500/500\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9566 - loss: 0.1321 - val_accuracy: 1.0000 - val_loss: 0.0860\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▄▄▄▄▅▅▅▅▅▅▆▆███████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃█████████████████████████</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1-score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96667</td></tr><tr><td>epoch/accuracy</td><td>0.9619</td></tr><tr><td>epoch/epoch</td><td>499</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.13152</td></tr><tr><td>epoch/val_accuracy</td><td>1</td></tr><tr><td>epoch/val_loss</td><td>0.08597</td></tr><tr><td>f1-score</td><td>0.9619</td></tr><tr><td>precision</td><td>0.95833</td></tr><tr><td>recall</td><td>0.9697</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mlp-experiment</strong> at: <a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris/runs/qcy1ey3y' target=\"_blank\">https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris/runs/qcy1ey3y</a><br> View project at: <a href='https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris' target=\"_blank\">https://wandb.ai/divyansh101-indian-institute-of-technology-gandhinagar/mlp-iris</a><br>Synced 5 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_174811-qcy1ey3y/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"mlp-iris\", name=\"mlp-experiment\")\n",
        "\n",
        "# Load Iris Dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)  # 10% validation, 20% test\n",
        "\n",
        "# Normalize features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Define the MLP Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(4,)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with updated W&B callbacks\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=500, batch_size=32,\n",
        "                    callbacks=[WandbMetricsLogger()])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "report = classification_report(y_test_classes, y_pred_classes, output_dict=True)\n",
        "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "\n",
        "# Log results to W&B\n",
        "wandb.log({\n",
        "    \"accuracy\": accuracy,\n",
        "    \"precision\": report['macro avg']['precision'],\n",
        "    \"recall\": report['macro avg']['recall'],\n",
        "    \"f1-score\": report['macro avg']['f1-score']\n",
        "})\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='d', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "plt.close()\n",
        "\n",
        "# Training vs Validation Loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "plt.close()\n",
        "\n",
        "# Upload Confusion Matrix and Loss Curve to W&B\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "wandb.log({\"loss_curve\": wandb.Image(plt)})\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8ub_RUq9tzlR"
      },
      "outputs": [],
      "source": [
        "# !pip show autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "20vprHiPv7Xj"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade autogluon.tabular[all] -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i6zxXADvw44j"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XE2J4Ac9Xffh",
        "outputId": "ed5b4757-540f-456e-9a9c-5acd1617da88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_174924\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.83 GB / 12.67 GB (85.4%)\n",
            "Disk Space Avail:   73.23 GB / 107.72 GB (68.0%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-02-26 17:49:27,452\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250226_174924/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Beginning AutoGluon training ... Time limit = 144s\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ag-20250226_174924/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Train Data Rows:    93\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Train Data Columns: 4\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Label Column:       species\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Problem Type:       multiclass\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Train Data Class Count: 3\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tAvailable Memory:                    10630.21 MB\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\t('float', []) : 4 | ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t\t('float', []) : 4 | ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t4 features in original data used to generate 4 features in processed data.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Data preprocessing and feature engineering runtime = 0.03s ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t'NN_TORCH': [{'num_epochs': 5, 'batch_size': 4, 'learning_rate': 0.001}],\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 95.82s of the 143.77s of remaining time.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.9785\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t37.66s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.06s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 143.77s of the 98.54s of remaining time.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.9785\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 98.53s of the 98.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.9892\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t29.95s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.06s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 143.77s of the 66.01s of remaining time.\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_BAG_L2': 1.0}\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.9892\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.0s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m AutoGluon training complete, total runtime = 77.8s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 96.8 rows/s (12 batch size)\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250226_174924/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=41657)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  NeuralNetTorch_BAG_L1       0.833333   0.978495    accuracy        0.032748       0.064169  37.663438                 0.032748                0.064169          37.663438            1       True          1\n",
            "1    WeightedEnsemble_L2       0.833333   0.978495    accuracy        0.033819       0.065081  37.669420                 0.001071                0.000912           0.005982            2       True          2\n",
            "2  NeuralNetTorch_BAG_L2       0.833333   0.989247    accuracy        0.068619       0.123864  67.614449                 0.035871                0.059695          29.951011            2       True          3\n",
            "3    WeightedEnsemble_L3       0.833333   0.989247    accuracy        0.069617       0.124550  67.617645                 0.000998                0.000685           0.003196            3       True          4\n",
            "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
            "\t86s\t = DyStack   runtime |\t514s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=0.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
            "Beginning AutoGluon training ... Time limit = 514s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250226_174924\"\n",
            "Train Data Rows:    105\n",
            "Train Data Columns: 4\n",
            "Label Column:       species\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9710.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{'num_epochs': 5, 'batch_size': 4, 'learning_rate': 0.001}],\n",
            "}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 513.77s of the 513.77s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.9619\t = Validation score   (accuracy)\n",
            "\t28.37s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 479.98s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
            "\t0.9619\t = Validation score   (accuracy)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 33.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 262.6 rows/s (14 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250226_174924\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 1.0000\n",
            "Test F1-score: 1.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGJCAYAAABYRTOkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW7tJREFUeJzt3XlYFdX/B/D3ZbsssgqyiYiAuCRo+JNQS00U3HLrK2oFmlK5lEYuUSGaFqm5a2puaLnvmXskWomaW2amiaG4sLnAFZTFe8/vD2Lqyr4OyPv1PPPInTlz5nPOHbkfZs6cqxBCCBARERHJREfuAIiIiKhuYzJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJUQ02dOhUKhQJ3796ttDqHDRuGxo0bV1p9dU1UVBQUCgWuX78urevcuTM6d+4sW0xPKyzGqhYTEwOFQoFt27ZVWp1ytIPkw2SEagWFQlGqJSYmRtY4O3fujOeee07WGJ5ljRs31nq/GzRogBdffBE7d+6UO7QyefToEaZOnSrr+VoVyS5ReenJHQBRaXzzzTdar9etW4fDhw8XWN+8efPqDItk0Lp1a3zwwQcAgDt37mD58uUYMGAAli5dinfeeafa4zl06FCZ93n06BGmTZsGADXqqgqRXJiMUK3w+uuva70+ceIEDh8+XGD90x49egRjY+OqDI2qmaOjo9b7HhQUBDc3N8ybN6/IZOTJkyfQaDQwMDCo9Hiqok6iuoa3aeiZkX+L5MyZM3jppZdgbGyMjz76CEDebZ6pU6cW2Kdx48YYNmyY1rq0tDSMHz8eTk5OUCqVcHNzw8yZM6HRaColzgsXLmDYsGFo0qQJDA0NYWdnhzfffBP37t0rtPzdu3cxaNAgmJmZoX79+hg3bhyysrIKlPv222/h7e0NIyMjWFlZYfDgwbh582aJ8WzatAne3t4wNTWFmZkZWrVqhQULFhRZPjc3F1ZWVhg+fHiBbSqVCoaGhpgwYYK0btGiRWjZsiWMjY1haWmJtm3bYsOGDSXGVVp2dnZo3rw54uPjAQDXr1+HQqHAl19+ifnz58PV1RVKpRKXLl0CAFy+fBmvvvoqrKysYGhoiLZt2+K7774rUO8ff/yBl19+GUZGRmjYsCFmzJhR6DlQ2JiRrKwsTJ06FU2bNoWhoSHs7e0xYMAAXLt2DdevX4eNjQ0AYNq0adItp/+en5UdY3ndv38fEyZMQKtWrVCvXj2YmZmhR48e+O233wotr1ar8dFHH8HOzg4mJiZ45ZVXCj0HT548iYCAAJibm8PY2BidOnXCL7/8UmI8p0+fhr+/P6ytrWFkZAQXFxe8+eabFW4nyY9XRuiZcu/ePfTo0QODBw/G66+/Dltb2zLt/+jRI3Tq1Am3b9/G22+/jUaNGuH48eMICwtDYmIi5s+fX+EYDx8+jL///hvDhw+HnZ0d/vjjD3z99df4448/cOLECSgUCq3ygwYNQuPGjREZGYkTJ05g4cKFePDgAdatWyeV+eyzzxAeHo5BgwZh5MiRSE1NxaJFi/DSSy/h3LlzsLCwKDKWIUOGoGvXrpg5cyYA4M8//8Qvv/yCcePGFbqPvr4++vfvjx07dmD58uVaVwZ27dqF7OxsDB48GACwYsUKvPfee3j11VelJOrChQs4efIkhg4dWpFulOTm5uLmzZuoX7++1vo1a9YgKysLb731FpRKJaysrPDHH3+gQ4cOcHR0xIcffggTExNs2bIF/fr1w/bt29G/f38AQFJSErp06YInT55I5b7++msYGRmVGI9arUbv3r0RHR2NwYMHY9y4cXj48CEOHz6Mixcvws/PD0uXLsWoUaPQv39/DBgwAADg6ekJANUSY2n9/fff2LVrF/73v//BxcUFycnJWL58OTp16oRLly7BwcFBq/xnn30GhUKByZMnIyUlBfPnz4efnx/Onz8vxfXjjz+iR48e8Pb2RkREBHR0dLBmzRq8/PLL+Omnn9CuXbtCY0lJSUH37t1hY2ODDz/8EBYWFrh+/Tp27NhRae0lGQmiWmjMmDHi6dO3U6dOAoBYtmxZgfIARERERIH1zs7OIjg4WHo9ffp0YWJiIv766y+tch9++KHQ1dUVCQkJxcbVqVMn0bJly2LLPHr0qMC6jRs3CgDi2LFj0rqIiAgBQLzyyitaZUePHi0AiN9++00IIcT169eFrq6u+Oyzz7TK/f7770JPT09rfXBwsHB2dpZejxs3TpiZmYknT54UG/PTDh48KACIPXv2aK3v2bOnaNKkifS6b9++JfZHWTg7O4vu3buL1NRUkZqaKn777TcxePBgAUC8++67Qggh4uPjBQBhZmYmUlJStPbv2rWraNWqlcjKypLWaTQa0b59e+Hu7i6tGz9+vAAgTp48Ka1LSUkR5ubmAoCIj4+X1nfq1El06tRJer169WoBQMydO7dA/BqNRgghRGpqapHnZFXEWJj88ys1NbXIMllZWUKtVmuti4+PF0qlUnz66afSuiNHjggAwtHRUahUKmn9li1bBACxYMECqR3u7u7C399f6gsh8v5PuLi4iG7duknr1qxZo9WOnTt3CgDi119/LbZdVDvxNg09U5RKZaG3D0pr69atePHFF2FpaYm7d+9Ki5+fH9RqNY4dO1bhGP/7l2tWVhbu3r2LF154AQBw9uzZAuXHjBmj9frdd98FAOzbtw8AsGPHDmg0GgwaNEgrZjs7O7i7u+PIkSNFxmJhYYHMzEwcPny4TG14+eWXYW1tjc2bN0vrHjx4gMOHDyMwMFCr/lu3buHXX38tU/3FOXToEGxsbGBjYwMvLy9s3boVb7zxhnRlJ9/AgQOl2yFA3i2HH3/8EYMGDcLDhw+lfrp37x78/f1x9epV3L59G0Be377wwgtaf6Xb2NjgtddeKzG+7du3w9raWnqf/uvpq15Pq64YS0upVEJHJ+9jQq1W4969e6hXrx48PDwKPVeDgoJgamoqvX711Vdhb28vnavnz5/H1atXMXToUNy7d09qX2ZmJrp27Ypjx44VeZsp/+re999/j9zc3EprI9UMvE1DzxRHR8cKDSi8evUqLly4oPUh9l8pKSnlrjvf/fv3MW3aNGzatKlAfenp6QXKu7u7a712dXWFjo6ONP/C1atXIYQoUC6fvr5+kbGMHj0aW7ZsQY8ePeDo6Iju3btj0KBBCAgIKLYNenp6GDhwIDZs2IDs7GwolUrs2LEDubm5WsnI5MmT8cMPP6Bdu3Zwc3ND9+7dMXToUHTo0KHY+ovj4+ODGTNmQKFQwNjYGM2bNy/0NpSLi4vW67i4OAghEB4ejvDw8ELrTklJgaOjI27cuAEfH58C2z08PEqM79q1a/Dw8ICeXtl/vVZXjKWl0WiwYMECfPXVV4iPj4darZa2PX1bDCh4rioUCri5uWmdqwAQHBxc5DHT09NhaWlZYH2nTp0wcOBATJs2DfPmzUPnzp3Rr18/DB06FEqlsjzNoxqEyQg9U8p6v/y/v1yBvF++3bp1w6RJkwot37Rp03LHlm/QoEE4fvw4Jk6ciNatW6NevXrQaDQICAgo1eDDp/+61mg0UCgU2L9/P3R1dQuUr1evXpF1NWjQAOfPn8fBgwexf/9+7N+/H2vWrEFQUBDWrl1bbByDBw/G8uXLsX//fvTr1w9btmxBs2bN4OXlJZVp3rw5rly5gu+//x4HDhzA9u3b8dVXX2HKlCnSo61lZW1tDT8/vxLLPX0u5PfthAkT4O/vX+g+bm5u5YqpstS0GD///HOEh4fjzTffxPTp02FlZQUdHR2MHz++XANl8/eZPXs2WrduXWiZos7X/EnVTpw4gT179uDgwYN48803MWfOHJw4caLY85xqPiYjVCdYWloiLS1Na11OTg4SExO11rm6uiIjI6NUH3bl8eDBA0RHR2PatGmYMmWKtD7/L8bCXL16Veuv/Li4OGg0GmkmVVdXVwgh4OLiUq5kycDAAH369EGfPn2g0WgwevRoLF++HOHh4cV+8L300kuwt7fH5s2b0bFjR/z444/4+OOPC5QzMTFBYGAgAgMDkZOTgwEDBuCzzz5DWFgYDA0NyxxveTVp0gRA3pWikt5fZ2fnQt+TK1eulHgcV1dXnDx5Erm5uUVelSrqdk11xVha27ZtQ5cuXbBq1Sqt9WlpabC2ti5Q/ul4hBCIi4uTBue6uroCAMzMzMr9f+yFF17ACy+8gM8++wwbNmzAa6+9hk2bNmHkyJHlqo9qBo4ZoTrB1dW1wHiPr7/+usCVkUGDBiE2NhYHDx4sUEdaWhqePHlSoTjyr1wIIbTWF/eUzpIlS7ReL1q0CADQo0cPAMCAAQOgq6uLadOmFahXCFHkI8MACmzT0dGRPjiys7OLaUle2VdffRV79uzBN998gydPnmjdoimsfgMDA7Ro0QJCCOm+/6NHj3D58uUqnwm0QYMG6Ny5M5YvX14gCQWA1NRU6eeePXvixIkTOHXqlNb29evXl3icgQMH4u7du1i8eHGBbfnvT/7cN08nyNUVY2np6uoWOKe2bt0qjVt52rp16/Dw4UPp9bZt25CYmCidq97e3nB1dcWXX36JjIyMAvv/t31Pe/DgQYFY8q+ulHSuUs3HKyNUJ4wcORLvvPMOBg4ciG7duuG3337DwYMHC/x1N3HiRHz33Xfo3bs3hg0bBm9vb2RmZuL333/Htm3bcP369UL/Ivyv1NRUzJgxo8B6FxcXvPbaa3jppZcwa9Ys5ObmwtHREYcOHZLmyChMfHw8XnnlFQQEBCA2Nhbffvsthg4dKt0OcXV1xYwZMxAWFobr16+jX79+MDU1RXx8PHbu3Im33npLa96Pp/vl/v37ePnll9GwYUPcuHEDixYtQuvWrUs1m21gYCAWLVqEiIgItGrVqsA+3bt3h52dHTp06ABbW1v8+eefWLx4MXr16iUNdDx16hS6dOmCiIiIQueCqUxLlixBx44d0apVK4SEhKBJkyZITk5GbGwsbt26Jc2fMWnSJHzzzTcICAjAuHHjpMdmnZ2dceHChWKPERQUhHXr1iE0NBSnTp3Ciy++iMzMTPzwww8YPXo0+vbtCyMjI7Ro0QKbN29G06ZNYWVlheeeew7PPfdctcT4X3Pnzi0wMaCOjg4++ugj9O7dG59++imGDx+O9u3b4/fff8f69eulKzhPs7KyQseOHTF8+HAkJydj/vz5cHNzQ0hIiFTvypUr0aNHD7Rs2RLDhw+Ho6Mjbt++jSNHjsDMzAx79uwptO61a9fiq6++Qv/+/eHq6oqHDx9ixYoVMDMzQ8+ePUvdXqqh5HmIh6hiinq0t6jHSNVqtZg8ebKwtrYWxsbGwt/fX8TFxRV4tFcIIR4+fCjCwsKEm5ubMDAwENbW1qJ9+/biyy+/FDk5OcXGlf94cWFL165dhRBC3Lp1S/Tv319YWFgIc3Nz8b///U/cuXOnwKOe+Y9eXrp0Sbz66qvC1NRUWFpairFjx4rHjx8XOPb27dtFx44dhYmJiTAxMRHNmjUTY8aMEVeuXJHKPP1o77Zt20T37t1FgwYNhIGBgWjUqJF4++23RWJiYrHtzKfRaISTk5MAIGbMmFFg+/Lly8VLL70k6tevL5RKpXB1dRUTJ04U6enpUpn8x0ILe8z1ac7OzqJXr17Flsl/tHf27NmFbr927ZoICgoSdnZ2Ql9fXzg6OorevXuLbdu2aZW7cOGC6NSpkzA0NBSOjo5i+vTpYtWqVSU+2itE3qOqH3/8sXBxcRH6+vrCzs5OvPrqq+LatWtSmePHjwtvb29hYGBQoP2VHWNh8s+vwhZdXV0hRN6jvR988IGwt7cXRkZGokOHDiI2NrZAm/Pfw40bN4qwsDDRoEEDYWRkJHr16iVu3LhR4Njnzp0TAwYMkM4LZ2dnMWjQIBEdHS2VefrR3rNnz4ohQ4aIRo0aCaVSKRo0aCB69+4tTp8+XWw7qXZQCPHUdS8iIiKiasQxI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCtOelYIjUaDO3fuwNTUtMRv2SQiIqJ/CSHw8OFDODg4SN/6XBImI4W4c+cOnJyc5A6DiIio1rp58yYaNmxYqrJMRgqRP031zZs3YWZmJnM0REREtYdKpYKTk5P0WVoaTEYKkX9rxszMjMkIERFROZRlmAMHsBIREZGsmIwQERGRrJiMEBERkayYjBAREZGsmIwQERGRrJiMEBERkaz4aG9NlZMJ5GZBbWSFU/H3kfIwCw1MDdHOxQq6j+8D+oaAgUnl7SdHrFT1eD48W2pb39a2eEk2siYjkZGR2LFjBy5fvgwjIyO0b98eM2fOhIeHR7H7bd26FeHh4bh+/Trc3d0xc+ZM9OzZU9ouhEBERARWrFiBtLQ0dOjQAUuXLoW7u3tVN6ly5GQCRz7HzaRkhNzuhcsqA2lTM7McrHDcCyc7W6DLR9r/kcu7nxyxUtXj+fBsqW19W9viJVnJepvm6NGjGDNmDE6cOIHDhw8jNzcX3bt3R2ZmZpH7HD9+HEOGDMGIESNw7tw59OvXD/369cPFixelMrNmzcLChQuxbNkynDx5EiYmJvD390dWVlZ1NKvicrNwMykZf8XFIfjRWlhCBQCwhArDHq3FX3FxuJmUDORmVc5+csRKVY/nw7OltvVtbYuXZCVrMnLgwAEMGzYMLVu2hJeXF6KiopCQkIAzZ84Uuc+CBQsQEBCAiRMnonnz5pg+fTqef/55LF68GEDeVZH58+fjk08+Qd++feHp6Yl169bhzp072LVrVzW1rGLURlYIud0LKcICNoo0TNLbDFfFbUzS2wxrRRpShQVCbveC2siqUvaTI1aqejwfni21rW9rW7wkrxo1gDU9PR0AYGVV9MkZGxsLPz8/rXX+/v6IjY0FAMTHxyMpKUmrjLm5OXx8fKQyT8vOzoZKpdJa5HQq/j4uqwww60kgUv/5jxymtwE2//wHnvkkEJdVBjgVf79S9pMjVqp6PB+eLbWtb2tbvCSvGpOMaDQajB8/Hh06dMBzzz1XZLmkpCTY2tpqrbO1tUVSUpK0PX9dUWWeFhkZCXNzc2mR+xt7Ux7mXbZ8ADOsVPfU2rZS3RMPYKZVrqL7yRErVT2eD8+W2ta3tS1ekleNSUbGjBmDixcvYtOmTdV+7LCwMKSnp0vLzZs3qz2G/2pgaggg797qSN19WttG6u6T7r3ml6vofnLESlWP58Ozpbb1bW2Ll+RVI5KRsWPH4vvvv8eRI0fQsGHDYsva2dkhOTlZa11ycjLs7Oyk7fnriirzNKVSKX1Db034pt52LlZoZpaDyXqbpUuakU+GSpc6J+ttRjOzHLRzsaqU/eSIlaoez4dnS23r29oWL8lL1mRECIGxY8di586d+PHHH+Hi4lLiPr6+voiOjtZad/jwYfj6+gIAXFxcYGdnp1VGpVLh5MmTUpmaTvfxfaxw3AsbRRruCgvMehKIa8IRs54E4u4//5FXOO7Ne06/EvaTI1aqejwfni21rW9rW7wkL1nnGRkzZgw2bNiA3bt3w9TUVBrTYW5uDiMjIwBAUFAQHB0dERkZCQAYN24cOnXqhDlz5qBXr17YtGkTTp8+ja+//hoAoFAoMH78eMyYMQPu7u5wcXFBeHg4HBwc0K9fP1naWWb6hnnP3wOYfbsXHvzzfP4DmCHKOPjf5/P1DStnPzliparH8+HZUtv6trbFS7JSCCGEbAdXKApdv2bNGgwbNgwA0LlzZzRu3BhRUVHS9q1bt+KTTz6RJj2bNWtWoZOeff3110hLS0PHjh3x1VdfoWnTpqWKS6VSwdzcHOnp6fLdsuEMrFQZeD48W2pb39a2eKlSlOczVNZkpKaqEckIERFRLVSez9AaMYCViIiI6i4mI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkK1mTkWPHjqFPnz5wcHCAQqHArl27ii0/bNgwKBSKAkvLli2lMlOnTi2wvVmzZlXcEiIiIiovWZORzMxMeHl5YcmSJaUqv2DBAiQmJkrLzZs3YWVlhf/9739a5Vq2bKlV7ueff66K8ImIiKgS6Ml58B49eqBHjx6lLm9ubg5zc3Pp9a5du/DgwQMMHz5cq5yenh7s7OwqLU4iIiKqOrV6zMiqVavg5+cHZ2dnrfVXr16Fg4MDmjRpgtdeew0JCQnF1pOdnQ2VSqW1EBERUfWotcnInTt3sH//fowcOVJrvY+PD6KionDgwAEsXboU8fHxePHFF/Hw4cMi64qMjJSuupibm8PJyamqwyciIqJ/KIQQQu4gAEChUGDnzp3o169fqcpHRkZizpw5uHPnDgwMDIosl5aWBmdnZ8ydOxcjRowotEx2djays7Ol1yqVCk5OTkhPT4eZmVmZ2kFERFSXqVQqmJubl+kzVNYxI+UlhMDq1avxxhtvFJuIAICFhQWaNm2KuLi4IssolUoolcrKDpOIiIhKoVbepjl69Cji4uKKvNLxXxkZGbh27Rrs7e2rITIiIiIqK1mTkYyMDJw/fx7nz58HAMTHx+P8+fPSgNOwsDAEBQUV2G/VqlXw8fHBc889V2DbhAkTcPToUVy/fh3Hjx9H//79oauriyFDhlRpW4iIiKh8ZL1Nc/r0aXTp0kV6HRoaCgAIDg5GVFQUEhMTCzwJk56eju3bt2PBggWF1nnr1i0MGTIE9+7dg42NDTp27IgTJ07Axsam6hpCRERE5VZjBrDWJOUZfENERETl+wytlWNGiIiI6NnBZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZCVrMnLs2DH06dMHDg4OUCgU2LVrV7HlY2JioFAoCixJSUla5ZYsWYLGjRvD0NAQPj4+OHXqVBW2goiIiCpC1mQkMzMTXl5eWLJkSZn2u3LlChITE6WlQYMG0rbNmzcjNDQUEREROHv2LLy8vODv74+UlJTKDp+IiIgqgZ6cB+/Rowd69OhR5v0aNGgACwuLQrfNnTsXISEhGD58OABg2bJl2Lt3L1avXo0PP/ywIuESERFRFaiVY0Zat24Ne3t7dOvWDb/88ou0PicnB2fOnIGfn5+0TkdHB35+foiNjS2yvuzsbKhUKq2FiIiIqketSkbs7e2xbNkybN++Hdu3b4eTkxM6d+6Ms2fPAgDu3r0LtVoNW1tbrf1sbW0LjCv5r8jISJibm0uLk5NTlbaDiIiI/iXrbZqy8vDwgIeHh/S6ffv2uHbtGubNm4dvvvmm3PWGhYUhNDRUeq1SqZiQEBERVZNalYwUpl27dvj5558BANbW1tDV1UVycrJWmeTkZNjZ2RVZh1KphFKprNI4iYiIqHC16jZNYc6fPw97e3sAgIGBAby9vREdHS1t12g0iI6Ohq+vr1whEhERUTFkvTKSkZGBuLg46XV8fDzOnz8PKysrNGrUCGFhYbh9+zbWrVsHAJg/fz5cXFzQsmVLZGVlYeXKlfjxxx9x6NAhqY7Q0FAEBwejbdu2aNeuHebPn4/MzEzp6RoiIiKqWWRNRk6fPo0uXbpIr/PHbQQHByMqKgqJiYlISEiQtufk5OCDDz7A7du3YWxsDE9PT/zwww9adQQGBiI1NRVTpkxBUlISWrdujQMHDhQY1EpEREQ1g0IIIeQOoqZRqVQwNzdHeno6zMzM5A6HiIio1ijPZ2itHzNCREREtRuTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSlazJyLFjx9CnTx84ODhAoVBg165dxZbfsWMHunXrBhsbG5iZmcHX1xcHDx7UKjN16lQoFAqtpVmzZlXYCiIiIqoIWZORzMxMeHl5YcmSJaUqf+zYMXTr1g379u3DmTNn0KVLF/Tp0wfnzp3TKteyZUskJiZKy88//1wV4RMREVEl0CtNoQsXLpS6Qk9Pz1KX7dGjB3r06FHq8vPnz9d6/fnnn2P37t3Ys2cP2rRpI63X09ODnZ1dqeslIiIi+ZQqGWndujUUCgWEEIVuz9+mUCigVqsrNcDiaDQaPHz4EFZWVlrrr169CgcHBxgaGsLX1xeRkZFo1KhRkfVkZ2cjOztbeq1SqaosZiIiItJWqmQkPj6+quMoly+//BIZGRkYNGiQtM7HxwdRUVHw8PBAYmIipk2bhhdffBEXL16EqalpofVERkZi2rRp1RU2ERER/YdCFHW5o5opFArs3LkT/fr1K1X5DRs2ICQkBLt374afn1+R5dLS0uDs7Iy5c+dixIgRhZYp7MqIk5MT0tPTYWZmVqZ2EBER1WUqlQrm5uZl+gwt1wDWb775Bh06dICDgwNu3LgBIG88x+7du8tTXZlt2rQJI0eOxJYtW4pNRADAwsICTZs2RVxcXJFllEolzMzMtBYiIiKqHmVORpYuXYrQ0FD07NkTaWlp0hgRCwuLAgNMq8LGjRsxfPhwbNy4Eb169SqxfEZGBq5duwZ7e/sqj42IiIjKrszJyKJFi7BixQp8/PHH0NXVlda3bdsWv//+e5nqysjIwPnz53H+/HkAeWNTzp8/j4SEBABAWFgYgoKCpPIbNmxAUFAQ5syZAx8fHyQlJSEpKQnp6elSmQkTJuDo0aO4fv06jh8/jv79+0NXVxdDhgwpa1OJiIioGpQ5GYmPj9d6jDafUqlEZmZmmeo6ffo02rRpI9UXGhqKNm3aYMqUKQCAxMREKTEBgK+//hpPnjzBmDFjYG9vLy3jxo2Tyty6dQtDhgyBh4cHBg0ahPr16+PEiROwsbEpa1OJiIioGpTqaZr/cnFxwfnz5+Hs7Ky1/sCBA2jevHmZ6urcuXORjwsDQFRUlNbrmJiYEuvctGlTmWIgIiIieZU5GQkNDcWYMWOQlZUFIQROnTqFjRs3IjIyEitXrqyKGImIiOgZVuZkZOTIkTAyMsInn3yCR48eYejQoXBwcMCCBQswePDgqoiRiIiInmEVmmfk0aNHyMjIQIMGDSozJtmV5xlpIiIiKt9naJmvjORLSUnBlStXAORNWMYBokRERFQeZU5GHj58iNGjR2Pjxo3QaDQAAF1dXQQGBmLJkiUwNzev9CCJiCiPWq1Gbm6u3GFQHaarqws9PT0oFIpKq7NcY0bOnTuHvXv3wtfXFwAQGxuLcePG4e233+bTLEREVSQjIwO3bt0q9ilEoupgbGwMe3t7GBgYVEp9ZR4zYmJigoMHD6Jjx45a63/66ScEBASUea6RmohjRoioplGr1bh69SqMjY1hY2NTqX+VEpWWEAI5OTlITU2FWq2Gu7s7dHS0pyyrljEj9evXL/RWjLm5OSwtLctaHRERlUJubi6EELCxsYGRkZHc4VAdZmRkBH19fdy4cQM5OTkwNDSscJ1lnoH1k08+QWhoKJKSkqR1SUlJmDhxIsLDwyscEBERFY1XRKgmePpqSEWV6spImzZttP4DXL16FY0aNUKjRo0AAAkJCVAqlUhNTcXbb79dqQESERHRs61UyUi/fv2qOAwiIiKqq0qVjERERFR1HERERDXW1KlTsWvXLulb5svj+vXrcHFxwblz59C6detKi+1ZULk3fYiIiP6hUCiKXaZOnVptsXTu3Bnjx4+vtuNR2ZT5aRq1Wo158+Zhy5YtSEhIQE5Ojtb2+/fvV1pwRERUudQagVPx95HyMAsNTA3RzsUKujpVMyg2MTFR+nnz5s2YMmWKNHM3ANSrV0/6WQgBtVoNPb1yTwxOtViZr4xMmzYNc+fORWBgINLT0xEaGooBAwZAR0enWrNcIiIqmwMXE9Fx5o8YsuIExm06jyErTqDjzB9x4GJiyTuXg52dnbSYm5tDoVBIry9fvgxTU1Ps378f3t7eUCqV+PnnnzFs2LAC4xTHjx+Pzp07S681Gg0iIyPh4uICIyMjeHl5Ydu2bRWKdfLkyWjatCmMjY3RpEkThIeHFzrT7fLly+Hk5ARjY2MMGjQI6enpWttXrlyJ5s2bw9DQEM2aNcNXX31V5DEfPHiA1157TXpc293dHWvWrKlQO2qrMqeg69evx4oVK9CrVy9MnToVQ4YMgaurKzw9PXHixAm89957VREnERFVwIGLiRj17Vk8PctlUnoWRn17Fktffx4Bz9lXe1wffvghvvzySzRp0qTUc1VFRkbi22+/xbJly+Du7o5jx47h9ddfh42NDTp16lSuOExNTREVFQUHBwf8/vvvCAkJgampKSZNmiSViYuLw5YtW7Bnzx6oVCqMGDECo0ePxvr16wHkfT5OmTIFixcvRps2bXDu3DmEhITAxMQEwcHBBY4ZHh6OS5cuYf/+/bC2tkZcXBweP35crvhruzInI0lJSWjVqhWAvEts+Vlh7969Oc8IEVENpNYITNtzqUAiAgACgALAtD2X0K2FXZXdsinKp59+im7dupW6fHZ2Nj7//HP88MMP0leSNGnSBD///DOWL19e7mTkk08+kX5u3LgxJkyYgE2bNmklI1lZWVi3bh0cHR0BAIsWLUKvXr0wZ84c2NnZISIiAnPmzMGAAQMAAC4uLrh06RKWL19eaDKSkJCANm3aoG3bttJx66oyJyMNGzZEYmIiGjVqBFdXVxw6dAjPP/88fv31VyiVyqqIkYiIKuBU/H0kpmcVuV0ASEzPwqn4+/B1rV99gQHSB3FpxcXF4dGjRwUSmJycHLRp06bccWzevBkLFy7EtWvXkJGRgSdPnhSYyrxRo0ZSIgIAvr6+0Gg0uHLlCkxNTXHt2jWMGDECISEhUpknT54U+QWyo0aNwsCBA3H27Fl0794d/fr1Q/v27cvdhtqszMlI//79ER0dDR8fH7z77rt4/fXXsWrVKiQkJOD999+vihiJiKgCUh4WnYiUp1xlMjEx0Xqto6NT4IsA/zt2IyMjAwCwd+9ercQAQLn/II6NjcVrr72GadOmwd/fH+bm5ti0aRPmzJlT6jry41qxYgV8fHy0tunq6ha6T48ePXDjxg3s27cPhw8fRteuXTFmzBh8+eWX5WpHbVbmZOSLL76Qfg4MDISzszOOHz8Od3d39OnTp1KDIyKiimtgWrrvDiltuapkY2ODixcvaq07f/489PX1AQAtWrSAUqlEQkJCuW/JPO348eNwdnbGxx9/LK27ceNGgXIJCQm4c+cOHBwcAAAnTpyAjo4OPDw8YGtrCwcHB/z999947bXXSn1sGxsbBAcHIzg4GC+++CImTpzIZKQ8XnjhBbzwwgtISUnB559/jo8++qgy4iIiokrSzsUK9uaGSErPKnTciAKAnXneY75ye/nllzF79mysW7cOvr6++Pbbb3Hx4kXpFoypqSkmTJiA999/HxqNBh07dkR6ejp++eUXmJmZFTo2I19qamqBScvs7e3h7u6OhIQEbNq0Cf/3f/+HvXv3YufOnQX2NzQ0RHBwML788kuoVCq89957GDRoEOzs7ADkPW363nvvwdzcHAEBAcjOzsbp06fx4MEDhIaGFqhvypQp8Pb2RsuWLZGdnY3vv/8ezZs3r0Dv1V6VNulZYmIiB7ASEdVAujoKRPRpASAv8fiv/NcRfVpU++DVwvj7+yM8PByTJk3C//3f/+Hhw4cICgrSKjN9+nSEh4cjMjISzZs3R0BAAPbu3QsXF5di696wYQPatGmjtaxYsQKvvPIK3n//fYwdOxatW7fG8ePHC/08c3Nzw4ABA9CzZ090794dnp6eWo/ujhw5EitXrsSaNWvQqlUrdOrUCVFRUUXGZWBggLCwMHh6euKll16Crq4uNm3aVI5eq/0U4umbc+X022+/4fnnn4dara6M6mSlUqlgbm6O9PT0AgOYiIjkkJWVhfj4eLi4uJT7K9sPXEzEtD2XtAaz2psbIqJPC1ke66Xaq7jzsTyfoZzqjuSVkwnkZkFtZFVwVsjH9wF9Q8DApPL3re5460o769Ixa9t7CiDgOXt0a2FXbTOwlptGDQgBoaOLzGw1nmg00NPRgYlSFwqNGlAoAJ3CB4VS7SRrMnLs2DHMnj0bZ86cQWJiInbu3FniNwTHxMQgNDQUf/zxB5ycnPDJJ59g2LBhWmWWLFmC2bNnIykpCV5eXli0aBHatWtXdQ2h8snJBI58jptJyQi53QuXVQbSpmZmOVjhuBdOdrZAl48K/mKuyL7VHW9daWddOmZte0//Q1dHUe2P75aJRg08TEJObi6u55ojS/1vomSoK9BYPx0G+vqAqR0TkmdIqZORwgbf/FdqamqZD56ZmQkvLy+8+eab0iQxxYmPj0evXr3wzjvvYP369YiOjsbIkSNhb28Pf39/AHnPioeGhmLZsmXw8fHB/Pnz4e/vjytXrqBBgwZljpGqUG4WbiYl46+4OASLtZiFQDyAGSyhwrBHm/FXXBoAwCk3q+Av5YrsW93x1pV21qVj1rb3tDYRAjm5ucjKzkZ93EMyLPEEutCDGtaaB8jKzhsKYFA5Iwyohij1ANZz584Vu9y6dQsvvfRSmQ7eo0cPzJgxA/379y9V+WXLlsHFxQVz5sxB8+bNMXbsWLz66quYN2+eVGbu3LkICQnB8OHD0aJFCyxbtgzGxsZYvXp1mWKjqqc2skLI7V5IERawUaRhkt5muCpuY5LeZlgr0pAqLBByuxfURgVH+Fdk3+qOt660sy4ds7a9p7WJ0NHF9Vxz5EIX+lDDVvEASuTCVvEAelDjCfK2C14VeaaUOhk5cuRIqZaqFBsbCz8/P611/v7+iI2NBZA3A9+ZM2e0yujo6MDPz08qU5js7GyoVCqthareqfj7uKwywKwngUj95xdzmN4G2PzzC3nmk0BcVhngVHzBb4KuyL7VHW9daWddOmZte09rk8xsNbLUCiQLSykhsVfchz7UyIUukoQlstQKZGbX/ocl6F+V9mhvdUhKSoKtra3WOltbW6hUKjx+/Bh3796FWq0utExSUlKR9UZGRsLc3FxanJycqiR+0pY/2+MDmGGluqfWtpXqnngAM61ylbVvdcdbV9pZl45Z297T2uSJRpP3L3RxV2hPo35XmOMJdLXK0bOhViUjVSUsLAzp6enScvPmTblDqhPyZ3u0hAojdfdpbRupuw+WUGmVq6x9qzveutLOunTM2vae1iZ6OnkfS3pQw1qRrrXNWpEOPai1ytGzoVa9m3Z2dkhOTtZal5ycDDMzMxgZGcHa2hq6urqFlsmfIa8wSqUSZmZmWgtVvXYuVmhmloPJepulS9SRT4ZKl64n621GM7OcQmeFrMi+1R1vXWlnXTpmbXtPaxMTpS4MdQXsFA+kWzOJwkq6ZWOneABDXQETJceMPEtqVTLi6+uL6OhorXWHDx+WvkbawMAA3t7eWmU0Gg2io6OlMlRz6D6+jxWOe2GjSMNdYYFZTwJxTThi1pNA3P3nF/MKx7158y5U4r7VHW9daWddOmZte09rE4VGjcb66dJg1WRhiWzoI1n8+1RNY/30vPlG6JkhazKSkZGB8+fPS98VEB8fj/PnzyMhIQFA3u2T/04D/M477+Dvv//GpEmTcPnyZXz11VfYsmWL1rcFh4aGYsWKFVi7di3+/PNPjBo1CpmZmRg+fHi1to1KQd8QTna2aOrmhijjYOle+QOYIco4GE3d3PLmW9Av5HJ1Rfat7njrSjvr0jFr23tamygUMNDXh6FSibs69f8dIwJd3NWpD0OlMm+eEUXBidqGDRumNVdV586dMX78+GoK/F8xMTFQKBRIS0ursmM83dbyqI44S02U0f79+8VPP/0kvV68eLHw8vISQ4YMEffv3y9TXUeOHBEACizBwcFCCCGCg4NFp06dCuzTunVrYWBgIJo0aSLWrFlToN5FixaJRo0aCQMDA9GuXTtx4sSJMsWVnp4uAIj09PQy7UflkJ0hRMZd8UStEcfj7opd526J43F5r0XG3bztVbFvdcdbV9pZl45Zzfs+fvxYXLp0STx+/LgSGl59goODpd/t+vr6wtXVVUybNk3k5uYWvZP6iRBPcoVGoxEPH+eKB5nZ4uHjvNfiSW7e9iKO1bdvX+n1vXv3hEqlKlWc+Z9HDx48KEPryl+Xs7OzmDdvXrmP8XRby6MibS7ufCzPZ2iZZ2CdOHEiZs6cCQD4/fff8cEHHyA0NBRHjhxBaGgo1qxZU+q6OnfuDFHMxDVRUVGF7nPu3Lli6x07dizGjh1b6jhIRgYmgIEJdIGCs0KalDBLZEX2La/yHrOutLMuHbO2vaf/TEFfaP2Z96psCnoACAgIwJo1a5CdnY19+/ZhzJgx0NfXR1hYWMEwc3JgYJA3K60CQD3Dpz6mdEv/sWVlVTfH3dRGZb5NEx8fjxYt8r79cfv27ejduzc+//xzLFmyBPv376/0AImIqIL+mYIe0VPzEo//yryXt/7I53nlqoBSqYSdnR2cnZ0xatQo+Pn54bvvvgPw7+2Gzz77DA4ODvDw8AAA3Lx5E4MGDYKFhQWsrKzQt29fXL9+XapTrVYjNDQUFhYWqF+/PiZNmlTgj9unb9NkZ2dj8uTJcHJyglKphJubG1atWoXr16+jS5cuAABLS0soFArpa0Y0Gg0iIyPh4uICIyMjeHl5Ydu2bVrH2bdvH5o2bQojIyN06dJFK87yUKvVGDFihHRMDw8PLFiwoNCy06ZNg42NDczMzPDOO+8gJydH2laa2P/rxo0b6NOnDywtLWFiYoKWLVti3759RZavTGW+MmJgYIBHjx4BAH744QdpTIeVlRUnCyMiqolys4BsFZCRkpd4dJ2ad4UkPxHJSPm3XDVMQW9kZIR79/5NiqKjo2FmZobDhw/nhZGbC39/f/j6+uKnn36Cnp4eZsyYgYCAAFy4cAEGBgaYM2cOoqKisHr1ajRv3hxz5szBzp078fLLLxd53KCgIMTGxmLhwoXw8vJCfHw87t69CycnJ2zfvh0DBw7ElStXpCc0gbx5qL799lssW7YM7u7uOHbsGF5//XXY2NigU6dOuHnzJgYMGIAxY8bgrbfewunTp/HBBx9UqH80Gg0aNmyIrVu3on79+jh+/Djeeust2NvbY9CgQVr9ZmhoiJiYGFy/fh3Dhw9H/fr18dlnn5Uq9qeNGTMGOTk5OHbsGExMTHDp0iXUq1evQm0ptbLeJ+rTp4/w9/cXn376qdDX1xe3bt0SQghx8OBB4e7uXtbqaiSOGSGimqbCY0Yy7gqxe6wQ6wfl/ZtyWft1xt3KDfgf/x3boNFoxOHDh4VSqRQTJkyQttva2ors7Gxpn2+++UZ4eHjkjRH5R3Z2tjAyMhIHDx4UQghhb28vZs2aJW3Pzc0VDRs21BpH0alTJzFu3DghhBBXrlwRAMThw4cLjbOw8RNZWVnC2NhYHD9+XKvsiBEjxJAhQ4QQQoSFhYkWLVpobZ88eXKljxkZM2aMGDhwoPQ6ODhYWFlZiczMTGnd0qVLRb169YRarS5V7E+3uVWrVmLq1Kmlikf2MSOLFy/G6NGjsW3bNixduhSOjo4AgP379yMgIKAS0yQiIqo0JvXzrojkXwk5PCVvfb0G/14pqSLff/896tWrh9zcXGg0GgwdOhRTp06Vtrdq1UoaJwIAv/32G+Li4mBqaqpVT1ZWFq5du4b09HQkJibCx8dH2qanp4e2bdsWOQ7x/Pnz0NXVLfSKQFHi4uLw6NEjdOvWTWt9Tk4O2rRpAwD4888/teIAUClTSSxZsgSrV69GQkICHj9+jJycHLRu3VqrjJeXF4yNjbWOm5GRgZs3byIjI6PE2J/23nvvYdSoUTh06BD8/PwwcOBAeHp6VrgtpVHmZKRRo0b4/vvvC6z/75fVERFRDWRSH/Ad+28iAuS9rsJEBAC6dOmCpUuXwsDAAA4ODtDT0/7oMTHRvjWUkZEBb29vrF+/vkBdNjY25Yoh/7ZLWWRkZAAA9u7dK/3hnU+pVJYrjtLYtGkTJkyYgDlz5sDX1xempqaYPXs2Tp48Weo6yhP7yJEj4e/vj7179+LQoUOIjIzEnDlz8O6775a/MaVU5gGsZ8+exe+//y693r17N/r164ePPvpIa+AMERHVMJn3gNjF2utiFxcc1FrJTExM4ObmhkaNGhVIRArz/PPP4+rVq2jQoAHc3Ny0lvzvELO3t9f6cH7y5AnOnDlTZJ2tWrWCRqPB0aNHC92ef2VGrf53MrUWLVpAqVQiISGhQBz532HWvHlznDp1SquuEydOlNjG4vzyyy9o3749Ro8ejTZt2sDNzQ3Xrl0rUO63337D48ePtY5br149ODk5lSr2wjg5OeGdd97Bjh078MEHH2DFihUVaktplTkZefvtt/HXX38BAP7++28MHjwYxsbG2Lp1KyZNmlTpARIRUSX472DVeg2Abp/m/Zs/qLWKE5KyeO2112BtbY2+ffvip59+Qnx8PGJiYvDee+/h1q1bAIBx48bhiy++wK5du3D58mWMHj262Mm7GjdujODgYLz55pvYtWuXVOeWLVsAAM7OzlAoFPj++++RmpqKjIwMmJqaYsKECXj//fexdu1aXLt2DWfPnsWiRYuwdu1aAHmTcV69ehUTJ07ElStXsGHDhkKnpSjM7du3pYk/85cHDx7A3d0dp0+fxsGDB/HXX38hPDwcv/76a4H9c3JyMGLECFy6dAn79u1DREQExo4dCx0dnVLF/rTx48fj4MGDiI+Px9mzZ3HkyBE0b968VG2psFKPLvmHmZmZiIuLE0II8cUXX4ju3bsLIYT4+eefRcOGDctaXY3EAaxEVNNUaADr04NX8werFrW+EpU0OVdR2xMTE0VQUJCwtrYWSqVSNGnSRISEhEi/l3Nzc8W4ceOEmZmZsLCwEKGhoSIoKKjIAaxC5PXh+++/L+zt7YWBgYFwc3MTq1evlrZ/+umnws7OTigUCmnyTY1GI+bPny88PDyEvr6+sLGxEf7+/uLo0aPSfnv27BFubm5CqVSKF198UaxevbpUA1hRyKSf33zzjcjKyhLDhg0T5ubmwsLCQowaNUp8+OGHwsvLq0C/TZkyRdSvX1/Uq1dPhISEiKysLKlMSbE/PYB17NixwtXVVSiVSmFjYyPeeOMNcfdu4edEZQ9gVQhRzKxjhTAzM8OZM2fg7u6Obt26oXfv3hg3bhwSEhLg4eGhdcmotlKpVDA3N0d6ejq/NI+IaoSsrCzEx8fDxcUFhoZlnCo+f56RbFXBwar5V0yUZkCXj6rl0V6q/Yo7H8vzGVrmAaxt27bFjBkz4Ofnh6NHj2Lp0qUA8iZDs7W1LWt1RERU1QxM8hKNwmZgzX/KpgpnYCUqSZnHjMyfPx9nz57F2LFj8fHHH8PNzQ0AsG3bNrRv377SAyQiokpgYFL0UzMm9ZmIkKzKfGXE09NT62mafLNnz4aurm6lBEVERER1R5mTkaKU+R4mEREREcqRjKjVasybNw9btmxBQkJCgblF7t+/X2nBERGRtjI+c0BUJSr7PCzzmJFp06Zh7ty5CAwMRHp6OkJDQzFgwADo6OhoTe9LRESVJ/82OCeXpJog/wtz9fX1K6W+Ml8ZWb9+PVasWIFevXph6tSpGDJkCFxdXeHp6YkTJ07gvffeq5TAiIjoX3p6ejA2NkZqair09fWho1PmvyWJKkwIgUePHiElJQUWFhaVNla0zMlIUlISWrVqBQCoV68e0tPTAQC9e/dGeHh4pQRFRETaFAoF7O3tER8fjxs3bsgdDtVxFhYWsLOzq7T6ypyMNGzYEImJiWjUqBFcXV1x6NAhPP/88/j111+r9IuDiIjqOgMDA7i7u/NWDclKX1+/0p+eLXMy0r9/f0RHR8PHxwfvvvsuXn/9daxatQoJCQl4//33KzU4IiLSpqOjw6cX6ZlT5ungnxYbG4vY2Fi4u7ujT58+lRWXrDgdPBERUflUy3TwT/P19YWvr29FqyEiIqI6qlTJyHfffVfqCl955ZVyB0NERER1T6mSkX79+pWqMoVCAbVaXZF4iIiIqI4pVTKi0WiqOg4iIiKqo2rErDlLlixB48aNYWhoCB8fH5w6darIsp07d4ZCoSiw9OrVSyozbNiwAtsDAgKqoylERERURqVORn788Ue0aNECKpWqwLb09HS0bNkSx44dK3MAmzdvRmhoKCIiInD27Fl4eXnB398fKSkphZbfsWMHEhMTpeXixYvQ1dXF//73P61yAQEBWuU2btxY5tiIiIio6pU6GZk/fz5CQkIKfUzH3Nwcb7/9NubNm1fmAObOnYuQkBAMHz4cLVq0wLJly2BsbIzVq1cXWt7Kygp2dnbScvjwYRgbGxdIRpRKpVY5S0vLMsdGREREVa/Uychvv/1W7K2O7t2748yZM2U6eE5ODs6cOQM/P79/A9LRgZ+fH2JjY0tVx6pVqzB48GCYmJhorY+JiUGDBg3g4eGBUaNG4d69e0XWkZ2dDZVKpbUQERFR9Sh1MpKcnFzst/Pp6ekhNTW1TAe/e/cu1Go1bG1ttdbb2toiKSmpxP1PnTqFixcvYuTIkVrrAwICsG7dOkRHR2PmzJk4evQoevToUeSTPpGRkTA3N5cWJyenMrWDiIiIyq/Uk545Ojri4sWLcHNzK3T7hQsXYG9vX2mBlcaqVavQqlUrtGvXTmv94MGDpZ9btWoFT09PuLq6IiYmBl27di1QT1hYGEJDQ6XXKpWKCQkREVE1KfWVkZ49eyI8PBxZWVkFtj1+/BgRERHo3bt3mQ5ubW0NXV1dJCcna61PTk4u8dsAMzMzsWnTJowYMaLE4zRp0gTW1taIi4srdLtSqYSZmZnWQkRERNWj1MnIJ598gvv376Np06aYNWsWdu/ejd27d2PmzJnw8PDA/fv38fHHH5fp4AYGBvD29kZ0dLS0TqPRIDo6usQp5rdu3Yrs7Gy8/vrrJR7n1q1buHfvXrVfuSEiIqKSlfo2ja2tLY4fP45Ro0YhLCwM+d+vp1Ao4O/vjyVLlhQY+1EaoaGhCA4ORtu2bdGuXTvMnz8fmZmZGD58OAAgKCgIjo6OiIyM1Npv1apV6NevH+rXr6+1PiMjA9OmTcPAgQNhZ2eHa9euYdKkSXBzc4O/v3+Z4yMiIqKqVaYvynN2dsa+ffvw4MEDxMXFQQgBd3f3Cj02GxgYiNTUVEyZMgVJSUlo3bo1Dhw4ICU2CQkJ0NHRvoBz5coV/Pzzzzh06FCB+nR1dXHhwgWsXbsWaWlpcHBwQPfu3TF9+nQolcpyx0lERERVQyHyL3GQpDxff0xERETl+wytEdPBExERUd3FZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZFUjkpElS5agcePGMDQ0hI+PD06dOlVk2aioKCgUCq3F0NBQq4wQAlOmTIG9vT2MjIzg5+eHq1evVnUziIiIqBxkT0Y2b96M0NBQRERE4OzZs/Dy8oK/vz9SUlKK3MfMzAyJiYnScuPGDa3ts2bNwsKFC7Fs2TKcPHkSJiYm8Pf3R1ZWVlU3h4iIiMpI9mRk7ty5CAkJwfDhw9GiRQssW7YMxsbGWL16dZH7KBQK2NnZSYutra20TQiB+fPn45NPPkHfvn3h6emJdevW4c6dO9i1a1c1tIiIiIjKQtZkJCcnB2fOnIGfn5+0TkdHB35+foiNjS1yv4yMDDg7O8PJyQl9+/bFH3/8IW2Lj49HUlKSVp3m5ubw8fEpss7s7GyoVCqthYiIiKqHrMnI3bt3oVarta5sAICtrS2SkpIK3cfDwwOrV6/G7t278e2330Kj0aB9+/a4desWAEj7laXOyMhImJubS4uTk1NFm0ZERESlJPttmrLy9fVFUFAQWrdujU6dOmHHjh2wsbHB8uXLy11nWFgY0tPTpeXmzZuVGDEREREVR9ZkxNraGrq6ukhOTtZan5ycDDs7u1LVoa+vjzZt2iAuLg4ApP3KUqdSqYSZmZnWQkRERNVD1mTEwMAA3t7eiI6OltZpNBpER0fD19e3VHWo1Wr8/vvvsLe3BwC4uLjAzs5Oq06VSoWTJ0+Wuk4iIiKqPnpyBxAaGorg4GC0bdsW7dq1w/z585GZmYnhw4cDAIKCguDo6IjIyEgAwKeffooXXngBbm5uSEtLw+zZs3Hjxg2MHDkSQN6TNuPHj8eMGTPg7u4OFxcXhIeHw8HBAf369ZOrmURERFQE2ZORwMBApKamYsqUKUhKSkLr1q1x4MABaQBqQkICdHT+vYDz4MEDhISEICkpCZaWlvD29sbx48fRokULqcykSZOQmZmJt956C2lpaejYsSMOHDhQYHI0IiIikp9CCCHkDqKmUalUMDc3R3p6OsePEBERlUF5PkNr3dM0RERE9GxhMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsqoRyciSJUvQuHFjGBoawsfHB6dOnSqy7IoVK/Diiy/C0tISlpaW8PPzK1B+2LBhUCgUWktAQEBVN4OIiIjKQfZkZPPmzQgNDUVERATOnj0LLy8v+Pv7IyUlpdDyMTExGDJkCI4cOYLY2Fg4OTmhe/fuuH37tla5gIAAJCYmSsvGjRurozlERERURgohhJAzAB8fH/zf//0fFi9eDADQaDRwcnLCu+++iw8//LDE/dVqNSwtLbF48WIEBQUByLsykpaWhl27dpUrJpVKBXNzc6Snp8PMzKxcdRAREdVF5fkMlfXKSE5ODs6cOQM/Pz9pnY6ODvz8/BAbG1uqOh49eoTc3FxYWVlprY+JiUGDBg3g4eGBUaNG4d69e0XWkZ2dDZVKpbUQERFR9ZA1Gbl79y7UajVsbW211tva2iIpKalUdUyePBkODg5aCU1AQADWrVuH6OhozJw5E0ePHkWPHj2gVqsLrSMyMhLm5ubS4uTkVP5GERERUZnoyR1ARXzxxRfYtGkTYmJiYGhoKK0fPHiw9HOrVq3g6ekJV1dXxMTEoGvXrgXqCQsLQ2hoqPRapVIxISEiIqomsl4Zsba2hq6uLpKTk7XWJycnw87Orth9v/zyS3zxxRc4dOgQPD09iy3bpEkTWFtbIy4urtDtSqUSZmZmWgsRERFVD1mTEQMDA3h7eyM6Olpap9FoEB0dDV9f3yL3mzVrFqZPn44DBw6gbdu2JR7n1q1buHfvHuzt7SslbiIiIqo8sj/aGxoaihUrVmDt2rX4888/MWrUKGRmZmL48OEAgKCgIISFhUnlZ86cifDwcKxevRqNGzdGUlISkpKSkJGRAQDIyMjAxIkTceLECVy/fh3R0dHo27cv3Nzc4O/vL0sbiYiIqGiyjxkJDAxEamoqpkyZgqSkJLRu3RoHDhyQBrUmJCRAR+ffnGnp0qXIycnBq6++qlVPREQEpk6dCl1dXVy4cAFr165FWloaHBwc0L17d0yfPh1KpbJa20ZEREQlk32ekZqI84wQERGVT62bZ4SIiIiIyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJiskIERERyYrJCBEREcmKyQgRERHJSk/uAJ5pOZlAbhbURlY4FX8fKQ+z0MDUEO1crKD7+D6gbwgYmMgd5b9qW7zlVVfaWZfwPS1ZefuotvVtReKVo49q0zGrUI1IRpYsWYLZs2cjKSkJXl5eWLRoEdq1a1dk+a1btyI8PBzXr1+Hu7s7Zs6ciZ49e0rbhRCIiIjAihUrkJaWhg4dOmDp0qVwd3evjubkyckEjnyOm0nJCLndC5dVBtKmZmY5WOG4F052tkCXj2rGf+TaFm951ZV21iV8T0tW3j6qbX1bkXjl6KPadMwqJvttms2bNyM0NBQRERE4e/YsvLy84O/vj5SUlELLHz9+HEOGDMGIESNw7tw59OvXD/369cPFixelMrNmzcLChQuxbNkynDx5EiYmJvD390dWVlZ1NQvIzcLNpGT8FReH4EdrYQkVAMASKgx7tBZ/xcXhZlIykFuNMRWntsVbXnWlnXUJ39OSlbePalvfViReOfqoNh2zismejMydOxchISEYPnw4WrRogWXLlsHY2BirV68utPyCBQsQEBCAiRMnonnz5pg+fTqef/55LF68GEDeVZH58+fjk08+Qd++feHp6Yl169bhzp072LVrV7W1S21khZDbvZAiLGCjSMMkvc1wVdzGJL3NsFakIVVYIOR2L6iNrKotpuLUtnjLq660sy7he1qy8vZRbevbisQrRx/VpmNWNVmTkZycHJw5cwZ+fn7SOh0dHfj5+SE2NrbQfWJjY7XKA4C/v79UPj4+HklJSVplzM3N4ePjU2Sd2dnZUKlUWktFnYq/j8sqA8x6EojUf970ML0NsPnnzZ75JBCXVQY4FX+/wseqDLUt3vKqK+2sS/ielqy8fVTb+rYi8crRR7XpmFVN1mTk7t27UKvVsLW11Vpva2uLpKSkQvdJSkoqtnz+v2WpMzIyEubm5tLi5ORUrvb8V8rDvEtcD2CGleqeWttWqnviAcy0ysmttsVbXnWlnXUJ39OSlbePalvfViReOfqoNh2zqsl+m6YmCAsLQ3p6urTcvHmzwnU2MDUEkHcfbqTuPq1tI3X3Sffp8svJrbbFW151pZ11Cd/TkpW3j2pb31YkXjn6qDYds6rJmoxYW1tDV1cXycnJWuuTk5NhZ2dX6D52dnbFls//tyx1KpVKmJmZaS0V1c7FCs3McjBZb7N0+SvyyVDpsthkvc1oZpaDdi41415rbYu3vOpKO+sSvqclK28f1ba+rUi8cvRRbTpmVZM1GTEwMIC3tzeio6OldRqNBtHR0fD19S10H19fX63yAHD48GGpvIuLC+zs7LTKqFQqnDx5ssg6q4Lu4/tY4bgXNoo03BUWmPUkENeEI2Y9CcTdf970FY57857prgFqW7zlVVfaWZfwPS1ZefuotvVtReKVo49q0zGrmuzzjISGhiI4OBht27ZFu3btMH/+fGRmZmL48OEAgKCgIDg6OiIyMhIAMG7cOHTq1Alz5sxBr169sGnTJpw+fRpff/01AEChUGD8+PGYMWMG3N3d4eLigvDwcDg4OKBfv37V1zB9w7xntQHMvt0LD/55lvsBzBBlHPzvs9z6NePyZq2Lt7zqSjvrEr6nJStvH9W2vq1IvHL0UW06ZhVTCCFEtR6xEIsXL5YmPWvdujUWLlwIHx8fAEDnzp3RuHFjREVFSeW3bt2KTz75RJr0bNasWYVOevb1118jLS0NHTt2xFdffYWmTZuWKh6VSgVzc3Okp6dX7JZNDZzlrli1Ld7yqivtrEv4npaMM7A+W7Oh1uAZWMvzGVojkpGaptKSESIiojqmPJ+hfJqGiIiIZMVkhIiIiGTFZISIiIhkxWSEiIiIZMVkhIiIiGTFZISIiIhkJfukZzVR/tPOlfHtvURERHVJ/mdnWWYOYTJSiIcPHwJApXx7LxERUV308OFDmJubl6osJz0rhEajwZ07d2BqagqFQlEpdapUKjg5OeHmzZucSK0I7KOSsY9Kxj4qGfuoZOyj4hXXP0IIPHz4EA4ODtDRKd1oEF4ZKYSOjg4aNmxYJXVX1rcCP8vYRyVjH5WMfVQy9lHJ2EfFK6p/SntFJB8HsBIREZGsmIwQERGRrJiMVBOlUomIiAgolUq5Q6mx2EclYx+VjH1UMvZRydhHxavs/uEAViIiIpIVr4wQERGRrJiMEBERkayYjBAREZGsmIwQERGRrJiMVJMlS5agcePGMDQ0hI+PD06dOiV3SDXG1KlToVAotJZmzZrJHZasjh07hj59+sDBwQEKhQK7du3S2i6EwJQpU2Bvbw8jIyP4+fnh6tWr8gQrk5L6aNiwYQXOq4CAAHmClUFkZCT+7//+D6ampmjQoAH69euHK1euaJXJysrCmDFjUL9+fdSrVw8DBw5EcnKyTBFXv9L0UefOnQucR++8845MEVe/pUuXwtPTU5rczNfXF/v375e2V9Y5xGSkGmzevBmhoaGIiIjA2bNn4eXlBX9/f6SkpMgdWo3RsmVLJCYmSsvPP/8sd0iyyszMhJeXF5YsWVLo9lmzZmHhwoVYtmwZTp48CRMTE/j7+yMrK6uaI5VPSX0EAAEBAVrn1caNG6sxQnkdPXoUY8aMwYkTJ3D48GHk5uaie/fuyMzMlMq8//772LNnD7Zu3YqjR4/izp07GDBggIxRV6/S9BEAhISEaJ1Hs2bNkini6tewYUN88cUXOHPmDE6fPo2XX34Zffv2xR9//AGgEs8hQVWuXbt2YsyYMdJrtVotHBwcRGRkpIxR1RwRERHCy8tL7jBqLABi586d0muNRiPs7OzE7NmzpXVpaWlCqVSKjRs3yhCh/J7uIyGECA4OFn379pUlnpooJSVFABBHjx4VQuSdM/r6+mLr1q1SmT///FMAELGxsXKFKaun+0gIITp16iTGjRsnX1A1kKWlpVi5cmWlnkO8MlLFcnJycObMGfj5+UnrdHR04Ofnh9jYWBkjq1muXr0KBwcHNGnSBK+99hoSEhLkDqnGio+PR1JSktY5ZW5uDh8fH55TT4mJiUGDBg3g4eGBUaNG4d69e3KHJJv09HQAgJWVFQDgzJkzyM3N1TqPmjVrhkaNGtXZ8+jpPsq3fv16WFtb47nnnkNYWBgePXokR3iyU6vV2LRpEzIzM+Hr61up5xC/KK+K3b17F2q1Gra2tlrrbW1tcfnyZZmiqll8fHwQFRUFDw8PJCYmYtq0aXjxxRdx8eJFmJqayh1ejZOUlAQAhZ5T+dso7xbNgAED4OLigmvXruGjjz5Cjx49EBsbC11dXbnDq1YajQbjx49Hhw4d8NxzzwHIO48MDAxgYWGhVbaunkeF9READB06FM7OznBwcMCFCxcwefJkXLlyBTt27JAx2ur1+++/w9fXF1lZWahXrx527tyJFi1a4Pz585V2DjEZIdn16NFD+tnT0xM+Pj5wdnbGli1bMGLECBkjo9ps8ODB0s+tWrWCp6cnXF1dERMTg65du8oYWfUbM2YMLl68WOfHYhWnqD566623pJ9btWoFe3t7dO3aFdeuXYOrq2t1hykLDw8PnD9/Hunp6di2bRuCg4Nx9OjRSj0Gb9NUMWtra+jq6hYYXZycnAw7OzuZoqrZLCws0LRpU8TFxckdSo2Uf97wnCqbJk2awNraus6dV2PHjsX333+PI0eOoGHDhtJ6Ozs75OTkIC0tTat8XTyPiuqjwvj4+ABAnTqPDAwM4ObmBm9vb0RGRsLLywsLFiyo1HOIyUgVMzAwgLe3N6Kjo6V1Go0G0dHR8PX1lTGymisjIwPXrl2Dvb293KHUSC4uLrCzs9M6p1QqFU6ePMlzqhi3bt3CvXv36sx5JYTA2LFjsXPnTvz4449wcXHR2u7t7Q19fX2t8+jKlStISEioM+dRSX1UmPPnzwNAnTmPCqPRaJCdnV2551DljrGlwmzatEkolUoRFRUlLl26JN566y1hYWEhkpKS5A6tRvjggw9ETEyMiI+PF7/88ovw8/MT1tbWIiUlRe7QZPPw4UNx7tw5ce7cOQFAzJ07V5w7d07cuHFDCCHEF198ISwsLMTu3bvFhQsXRN++fYWLi4t4/PixzJFXn+L66OHDh2LChAkiNjZWxMfHix9++EE8//zzwt3dXWRlZckderUYNWqUMDc3FzExMSIxMVFaHj16JJV55513RKNGjcSPP/4oTp8+LXx9fYWvr6+MUVevkvooLi5OfPrpp+L06dMiPj5e7N69WzRp0kS89NJLMkdefT788ENx9OhRER8fLy5cuCA+/PBDoVAoxKFDh4QQlXcOMRmpJosWLRKNGjUSBgYGol27duLEiRNyh1RjBAYGCnt7e2FgYCAcHR1FYGCgiIuLkzssWR05ckQAKLAEBwcLIfIe7w0PDxe2trZCqVSKrl27iitXrsgbdDUrro8ePXokunfvLmxsbIS+vr5wdnYWISEhdeoPgML6BoBYs2aNVObx48di9OjRwtLSUhgbG4v+/fuLxMRE+YKuZiX1UUJCgnjppZeElZWVUCqVws3NTUycOFGkp6fLG3g1evPNN4Wzs7MwMDAQNjY2omvXrlIiIkTlnUMKIYQo55UaIiIiogrjmBEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESKqsRQKBXbt2iV3GJg6dSpat24tdxhEzywmI0R1WGpqKkaNGoVGjRpBqVTCzs4O/v7++OWXX+QOrVJcv34dCoVC+nIzIqqZ9OQOgIjkM3DgQOTk5GDt2rVo0qQJkpOTER0djXv37skdGhHVIbwyQlRHpaWl4aeffsLMmTPRpUsXODs7o127dggLC8Mrr7wilZs7dy5atWoFExMTODk5YfTo0cjIyJC2R0VFwcLCAt9//z08PDxgbGyMV199FY8ePcLatWvRuHFjWFpa4r333oNarZb2a9y4MaZPn44hQ4bAxMQEjo6OWLJkSbEx37x5E4MGDYKFhQWsrKzQt29fXL9+vdRtjomJgUKhQHR0NNq2bQtjY2O0b98eV65c0Sr3xRdfwNbWFqamphgxYgSysrIK1LVy5Uo0b94choaGaNasGb766itp25tvvglPT09kZ2cDAHJyctCmTRsEBQWVOlaiOqXyvtuPiGqT3NxcUa9ePTF+/HiRlZVVZLl58+aJH3/8UcTHx4vo6Gjh4eEhRo0aJW1fs2aN0NfXF926dRNnz54VR48eFfXr1xfdu3cXgwYNEn/88YfYs2ePMDAwEJs2bZL2c3Z2FqampiIyMlJcuXJFLFy4UOjq6mp9IygAsXPnTiGEEDk5OaJ58+bizTffFBcuXBCXLl0SQ4cOFR4eHiI7O7vQ2OPj4wUAce7cOSHEv9/06+PjI2JiYsQff/whXnzxRdG+fXtpn82bNwulUilWrlwpLl++LD7++GNhamoqvLy8pDLffvutsLe3F9u3bxd///232L59u7CyshJRUVFCCCEePnwomjRpIsaPHy+EEGLChAmicePGderbXonKgskIUR22bds2YWlpKQwNDUX79u1FWFiY+O2334rdZ+vWraJ+/frS6zVr1ggAIi4uTlr39ttvC2NjY/Hw4UNpnb+/v3j77bel187OziIgIECr7sDAQNGjRw/p9X+TkW+++UZ4eHgIjUYjbc/OzhZGRkbi4MGDhcZaVDLyww8/SGX27t0rAIjHjx8LIYTw9fUVo0eP1qrHx8dHKxlxdXUVGzZs0Cozffp04evrK70+fvy40NfXF+Hh4UJPT0/89NNPhcZIRELwNg1RHTZw4EDcuXMH3333HQICAhATE4Pnn38eUVFRUpkffvgBXbt2haOjI0xNTfHGG2/g3r17ePTokVTG2NgYrq6u0mtbW1s0btwY9erV01qXkpKidXxfX98Cr//8889CY/3tt98QFxcHU1NT1KtXD/Xq1YOVlRWysrJw7dq1MrXb09NT+tne3h4ApNj+/PNP+Pj4FBlnZmYmrl27hhEjRkhx1KtXDzNmzNCKw9fXFxMmTMD06dPxwQcfoGPHjmWKkagu4QBWojrO0NAQ3bp1Q7du3RAeHo6RI0ciIiICw4YNw/Xr19G7d2+MGjUKn332GaysrPDzzz9jxIgRyMnJgbGxMQBAX19fq06FQlHoOo1GU+44MzIy4O3tjfXr1xfYZmNjU6a6/hubQqEAgFLHlj9eZsWKFQWSFl1dXelnjUaDX375Bbq6uoiLiytTfER1Da+MEJGWFi1aIDMzEwBw5swZaDQazJkzBy+88AKaNm2KO3fuVNqxTpw4UeB18+bNCy37/PPP4+rVq2jQoAHc3Ny0FnNz80qLqXnz5jh58mSRcdra2sLBwQF///13gThcXFykcrNnz8bly5dx9OhRHDhwAGvWrKm0GImeNUxGiOqoe/fu4eWXX8a3336LCxcuID4+Hlu3bsWsWbPQt29fAICbmxtyc3OxaNEi/P333/jmm2+wbNmySovhl19+waxZs/DXX39hyZIl2Lp1K8aNG1do2ddeew3W1tbo27cvfvrpJ8THxyMmJgbvvfcebt26VWkxjRs3DqtXr8aaNWvw119/ISIiAn/88YdWmWnTpiEyMhILFy7EX3/9hd9//x1r1qzB3LlzAQDnzp3DlClTsHLlSnTo0AFz587FuHHj8Pfff1danETPEiYjRHVUvXr14OPjg3nz5uGll17Cc889h/DwcISEhGDx4sUAAC8vL8ydOxczZ87Ec889h/Xr1yMyMrLSYvjggw9w+vRptGnTBjNmzMDcuXPh7+9faFljY2McO3YMjRo1woABA9C8eXPpsVszM7NKiykwMBDh4eGYNGkSvL29cePGDYwaNUqrzMiRI7Fy5UqsWbMGrVq1QqdOnRAVFQUXFxdkZWXh9ddfx7Bhw9CnTx8AwFtvvYUuXbrgjTfe0Hq8mYjyKIQQQu4giKjuady4McaPH4/x48fLHQoRyYxXRoiIiEhWTEaIiIhIVrxNQ0RERLLilREiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIiktX/A0NcBYOhwQ3lAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Inputs, Predictions, and True Labels:\n",
            "Input: [1.05882353 0.81818182 0.94642857 0.79166667], Predicted: virginica, True: virginica\n",
            "Input: [0.32352941 0.86363636 0.03571429 0.125     ], Predicted: setosa, True: setosa\n",
            "Input: [0.52941176 0.36363636 0.64285714 0.45833333], Predicted: versicolor, True: versicolor\n",
            "Input: [0.73529412 0.54545455 0.85714286 0.91666667], Predicted: virginica, True: virginica\n",
            "Input: [0.38235294 0.22727273 0.5        0.41666667], Predicted: versicolor, True: versicolor\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from autogluon.tabular import TabularPredictor\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset and define species names\n",
        "iris = load_iris()\n",
        "species_names = iris.target_names.tolist()\n",
        "\n",
        "# Convert data to pandas DataFrame for AutoGluon compatibility\n",
        "feature_columns = iris.feature_names  # Use original iris feature names\n",
        "X_train_df = pd.DataFrame(X_train, columns=feature_columns)\n",
        "X_test_df = pd.DataFrame(X_test, columns=feature_columns)\n",
        "y_train_df = pd.DataFrame(y_train.argmax(axis=1), columns=['species'])\n",
        "y_test_df = pd.DataFrame(y_test.argmax(axis=1), columns=['species'])\n",
        "\n",
        "# Map numerical labels to species names\n",
        "y_train_df['species'] = y_train_df['species'].map(lambda x: species_names[x])\n",
        "y_test_df['species'] = y_test_df['species'].map(lambda x: species_names[x])\n",
        "\n",
        "# Combine features and labels\n",
        "train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
        "test_data = pd.concat([X_test_df, y_test_df], axis=1)\n",
        "\n",
        "# Ensure label column is categorical\n",
        "train_data['species'] = train_data['species'].astype('category')\n",
        "test_data['species'] = test_data['species'].astype('category')\n",
        "\n",
        "# Define hyperparameter grid\n",
        "hyperparameters = {\n",
        "    'NN_TORCH': {\n",
        "        'num_epochs': 5,  # Max epochs, AutoGluon will tune within this\n",
        "        'batch_size': 4,  # AutoGluon will optimize this\n",
        "        'learning_rate': 1e-3  # AutoGluon will tune around this\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train AutoGluon model\n",
        "predictor = TabularPredictor(label='species').fit(\n",
        "    train_data,\n",
        "    hyperparameters=hyperparameters,\n",
        "    presets='best_quality',\n",
        "    time_limit=600  # Set a reasonable training time limit\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predictions = predictor.predict(test_data.drop(columns=['species']))\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(test_data['species'], predictions)\n",
        "f1 = f1_score(test_data['species'], predictions, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F1-score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_data['species'], predictions, labels=species_names)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_names)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Plot true labels vs. predicted labels\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(range(len(test_data)), test_data['species'].map(species_names.index), label='True Labels', marker='o')\n",
        "plt.scatter(range(len(predictions)), predictions.map(species_names.index), label='Predicted Labels', marker='x', alpha=0.7)\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Class Label\")\n",
        "plt.legend()\n",
        "plt.title(\"True Labels vs. Predicted Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Display five test samples\n",
        "sample_indices = np.random.choice(len(X_test_df), 5, replace=False)\n",
        "print(\"Sample Inputs, Predictions, and True Labels:\")\n",
        "for i in sample_indices:\n",
        "    print(f\"Input: {X_test_df.iloc[i].values}, Predicted: {predictions.iloc[i]}, True: {test_data.iloc[i]['species']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
